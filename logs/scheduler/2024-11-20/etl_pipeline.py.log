[2024-11-20T04:20:01.918+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:20:01.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:20:01.929+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:20:01.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:20:01.989+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:20:01.977+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:20:01.991+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:20:01.997+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:20:32.757+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:20:32.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:20:32.763+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:20:32.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:20:32.786+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:20:32.782+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:20:32.788+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:20:32.791+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:21:03.565+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:21:03.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:21:03.573+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:21:03.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:21:03.604+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:21:03.598+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:21:03.606+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:21:03.611+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:21:34.290+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:21:34.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:21:34.297+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:21:34.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:21:34.328+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:21:34.323+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:21:34.333+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:21:34.338+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:22:05.238+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:22:05.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:22:05.284+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:22:05.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:22:05.321+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:22:05.316+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:22:05.324+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:22:05.326+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:22:35.937+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:22:35.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:22:35.944+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:22:35.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:22:35.975+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:22:35.969+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:22:35.977+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:22:35.981+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:23:06.660+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:23:06.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:23:06.666+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:23:06.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:23:06.695+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:23:06.689+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:23:06.697+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:23:06.701+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:23:37.415+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:23:37.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:23:37.426+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:23:37.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:23:37.462+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:23:37.451+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:23:37.464+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:23:37.469+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:24:08.142+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:24:08.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:24:08.149+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:24:08.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:24:08.173+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:24:08.168+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:24:08.176+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:24:08.180+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:24:38.636+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:24:38.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:24:38.644+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:24:38.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:24:38.677+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:24:38.667+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:24:38.679+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:24:38.694+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T04:29:08.855+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:29:08.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:29:08.889+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:29:08.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:29:08.945+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:29:08.934+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:29:08.948+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:29:09.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.239 seconds
[2024-11-20T04:30:08.159+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:30:08.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:30:08.169+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:30:08.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:30:08.244+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:30:08.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:30:08.247+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:30:08.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.265 seconds
[2024-11-20T04:30:38.523+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:30:38.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:30:38.529+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:30:38.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:30:38.553+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:30:38.547+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:30:38.554+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:30:38.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.069 seconds
[2024-11-20T04:31:08.710+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:31:08.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:31:08.725+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:31:08.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:31:08.747+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:31:08.742+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:31:08.749+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:31:08.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.081 seconds
[2024-11-20T04:31:38.976+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:31:38.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:31:38.980+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:31:38.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:31:38.999+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:31:38.995+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:31:39.000+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:31:39.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.072 seconds
[2024-11-20T04:32:09.213+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:32:09.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:32:09.226+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:32:09.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:32:09.252+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:32:09.246+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:32:09.254+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:32:09.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.088 seconds
[2024-11-20T04:32:39.499+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:32:39.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:32:39.505+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:32:39.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:32:39.529+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:32:39.525+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:32:39.531+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:32:39.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.072 seconds
[2024-11-20T04:33:09.947+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:33:09.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:33:09.952+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:33:09.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:33:09.984+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:33:09.979+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:33:09.986+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:33:10.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.077 seconds
[2024-11-20T04:33:40.281+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:33:40.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:33:40.289+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:33:40.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:33:40.313+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:33:40.307+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:33:40.317+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:33:40.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.093 seconds
[2024-11-20T04:34:10.670+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:34:10.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:34:10.676+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:34:10.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:34:10.705+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:34:10.698+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:34:10.707+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:34:10.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.093 seconds
[2024-11-20T04:34:41.021+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:34:41.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:34:41.029+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:34:41.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:34:41.055+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:34:41.050+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:34:41.057+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:34:41.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.084 seconds
[2024-11-20T04:35:11.437+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:35:11.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:35:11.444+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:35:11.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:35:11.470+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:35:11.465+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:35:11.472+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:35:11.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.100 seconds
[2024-11-20T04:35:41.655+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:35:41.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:35:41.661+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:35:41.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:35:41.688+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:35:41.682+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:35:41.690+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:35:41.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.087 seconds
[2024-11-20T04:36:12.350+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:36:12.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:36:12.357+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:36:12.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:36:12.384+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:36:12.378+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:36:12.386+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:36:12.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.073 seconds
[2024-11-20T04:36:41.774+0000] {processor.py:186} INFO - Started process (PID=151) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:36:41.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:36:41.780+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:36:41.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:36:41.830+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:36:41.824+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:36:41.832+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:36:41.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.103 seconds
[2024-11-20T04:37:12.387+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:37:12.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:37:12.394+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:37:12.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:37:12.476+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:37:12.467+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:37:12.483+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:37:12.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.149 seconds
[2024-11-20T04:37:42.916+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:37:42.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:37:42.921+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:37:42.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:37:42.959+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:37:42.945+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:37:42.963+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:37:42.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.085 seconds
[2024-11-20T04:38:13.633+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:38:13.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:38:13.658+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:38:13.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:38:13.826+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:38:13.811+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:38:13.835+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:38:13.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.328 seconds
[2024-11-20T04:38:44.879+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:38:44.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:38:44.885+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:38:44.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:38:44.904+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:38:44.900+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:38:44.906+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:38:44.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.064 seconds
[2024-11-20T04:39:15.388+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:15.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:39:15.393+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:39:15.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:15.413+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:39:15.409+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import openmeteo_requests
ModuleNotFoundError: No module named 'openmeteo_requests'
[2024-11-20T04:39:15.416+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:15.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.066 seconds
[2024-11-20T04:39:30.703+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:30.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:39:30.709+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:39:30.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:30.763+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:39:30.756+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 19
    responses = 
                ^
SyntaxError: invalid syntax
[2024-11-20T04:39:30.765+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:30.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.105 seconds
[2024-11-20T04:39:30.881+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:30.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:39:30.887+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:39:30.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:30.920+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:39:30.917+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 19
    responses = 
                ^
SyntaxError: invalid syntax
[2024-11-20T04:39:30.923+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:39:30.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.097 seconds
[2024-11-20T04:40:01.491+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:01.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:40:01.496+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:40:01.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:01.526+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:40:01.525+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 19
    responses = 
                ^
SyntaxError: invalid syntax
[2024-11-20T04:40:01.527+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:01.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.099 seconds
[2024-11-20T04:40:11.717+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:11.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:40:11.733+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:40:11.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:11.822+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:40:11.820+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 21
    responses = 
                ^
SyntaxError: invalid syntax
[2024-11-20T04:40:11.825+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:11.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.162 seconds
[2024-11-20T04:40:42.211+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:42.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:40:42.216+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:40:42.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:42.242+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:40:42.240+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 21
    responses = 
                ^
SyntaxError: invalid syntax
[2024-11-20T04:40:42.243+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:40:42.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.069 seconds
[2024-11-20T04:41:13.058+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:41:13.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:41:13.082+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:13.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:41:13.156+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:13.154+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 21
    responses = 
                ^
SyntaxError: invalid syntax
[2024-11-20T04:41:13.158+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:41:13.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.168 seconds
[2024-11-20T04:41:21.376+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:41:21.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:41:21.382+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:21.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:41:27.995+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:41:33.174+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.173+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:weather_data_pipeline
[2024-11-20T04:41:33.201+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.200+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:weather_data_pipeline
[2024-11-20T04:41:33.218+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.217+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:weather_data_pipeline
[2024-11-20T04:41:33.236+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.236+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:weather_data_pipeline
[2024-11-20T04:41:33.254+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.253+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:weather_data_pipeline
[2024-11-20T04:41:33.274+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.273+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:weather_data_pipeline
[2024-11-20T04:41:33.293+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.293+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:weather_data_pipeline
[2024-11-20T04:41:33.295+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:41:33.342+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.341+0000] {dag.py:3262} INFO - Creating ORM DAG for weather_data_pipeline
[2024-11-20T04:41:33.367+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:41:33.367+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:41:33.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 10.897 seconds
[2024-11-20T04:42:03.925+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:42:03.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:42:04.253+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:42:04.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:42:06.024+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:42:07.138+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:42:07.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:42:07.256+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:42:07.255+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:42:07.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.553 seconds
[2024-11-20T04:42:37.816+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:42:37.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:42:37.823+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:42:37.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:42:38.363+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:42:38.397+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:42:38.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:42:38.431+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:42:38.431+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:42:38.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.020 seconds
[2024-11-20T04:43:09.326+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:43:09.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:43:09.332+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:43:09.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:43:09.831+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:43:09.866+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:43:09.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:43:09.903+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:43:09.903+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:43:11.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.028 seconds
[2024-11-20T04:43:42.583+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:43:42.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:43:42.592+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:43:42.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:43:43.649+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:43:43.684+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:43:43.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:43:43.976+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:43:43.976+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:43:44.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.444 seconds
[2024-11-20T04:44:00.499+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:00.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:44:00.506+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:00.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:01.379+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:01.433+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:01.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:44:01.506+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:01.505+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:44:01.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.079 seconds
[2024-11-20T04:44:11.806+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:11.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:44:11.823+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:11.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:13.668+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:13.709+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:13.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:44:13.757+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:13.756+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:44:13.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.010 seconds
[2024-11-20T04:44:45.499+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:45.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:44:45.509+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:45.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:46.440+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:44:46.491+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:46.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:44:46.546+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:44:46.546+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:44:46.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.103 seconds
[2024-11-20T04:45:17.373+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:45:17.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:45:17.380+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:45:17.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:45:18.329+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:45:18.402+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:45:18.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:45:18.465+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:45:18.465+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:45:18.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.162 seconds
[2024-11-20T04:45:48.849+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:45:48.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T04:45:48.855+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:45:48.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:45:49.450+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T04:45:49.495+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:45:49.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T04:45:49.533+0000] {logging_mixin.py:190} INFO - [2024-11-20T04:45:49.533+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T04:45:49.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.054 seconds
[2024-11-20T05:54:55.152+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:54:55.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:54:55.158+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:54:55.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:55:01.438+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:55:04.594+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:04.590+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:weather_data_pipeline
[2024-11-20T05:55:04.937+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:04.936+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:weather_data_pipeline
[2024-11-20T05:55:05.160+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:05.159+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:weather_data_pipeline
[2024-11-20T05:55:06.538+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:06.538+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:weather_data_pipeline
[2024-11-20T05:55:10.726+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:10.726+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:weather_data_pipeline
[2024-11-20T05:55:12.317+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:12.316+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:weather_data_pipeline
[2024-11-20T05:55:12.626+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:12.625+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:weather_data_pipeline
[2024-11-20T05:55:12.635+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:12.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:55:15.760+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:15.760+0000] {dag.py:3262} INFO - Creating ORM DAG for weather_data_pipeline
[2024-11-20T05:55:15.780+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:15.780+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:55:15.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 19.462 seconds
[2024-11-20T05:55:46.803+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:55:46.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:55:46.822+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:46.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:55:48.778+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:55:48.850+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:48.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:55:48.899+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:55:48.899+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:55:48.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.151 seconds
[2024-11-20T05:56:19.614+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:56:19.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:56:19.619+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:56:19.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:56:20.068+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:56:20.119+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:56:20.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:56:20.150+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:56:20.149+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:56:20.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.569 seconds
[2024-11-20T05:56:50.376+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:56:50.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:56:50.381+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:56:50.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:56:50.830+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:56:50.864+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:56:50.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:56:50.895+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:56:50.895+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:56:50.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.556 seconds
[2024-11-20T05:57:21.614+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:57:21.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:57:21.619+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:57:21.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:57:22.053+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:57:22.083+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:57:22.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:57:22.113+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:57:22.113+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:57:22.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.533 seconds
[2024-11-20T05:57:52.329+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:57:52.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:57:52.334+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:57:52.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:57:52.775+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:57:52.806+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:57:52.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:57:52.836+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:57:52.836+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:57:52.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.551 seconds
[2024-11-20T05:58:23.720+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:58:23.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:58:23.725+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:58:23.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:58:24.155+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:58:24.189+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:58:24.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:58:24.221+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:58:24.220+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:58:24.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.545 seconds
[2024-11-20T05:58:54.474+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:58:54.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:58:54.480+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:58:54.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:58:54.974+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:58:55.031+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:58:55.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:58:55.076+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:58:55.075+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:58:55.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.668 seconds
[2024-11-20T05:59:25.828+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:59:25.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:59:25.833+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:59:25.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:59:26.326+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:59:26.369+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:59:26.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:59:26.405+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:59:26.405+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:59:26.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.622 seconds
[2024-11-20T05:59:56.548+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:59:56.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T05:59:56.553+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:59:56.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:59:57.013+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T05:59:57.044+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:59:57.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T05:59:57.074+0000] {logging_mixin.py:190} INFO - [2024-11-20T05:59:57.074+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T05:59:57.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.566 seconds
[2024-11-20T06:00:27.312+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:00:27.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:00:27.317+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:00:27.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:00:27.748+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:00:27.786+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:00:27.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:00:27.816+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:00:27.816+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:00:27.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.551 seconds
[2024-11-20T06:00:58.661+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:00:58.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:00:58.666+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:00:58.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:00:59.124+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:00:59.153+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:00:59.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:00:59.183+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:00:59.183+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:00:59.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.569 seconds
[2024-11-20T06:01:29.519+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:01:29.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:01:29.525+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:01:29.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:01:30.000+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:01:30.029+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:01:30.029+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:01:30.060+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:01:30.060+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:01:30.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.585 seconds
[2024-11-20T06:02:01.724+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:02:01.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:02:01.788+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:02:01.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:06:39.237+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:06:39.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:06:39.244+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:06:39.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:06:42.342+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:06:43.101+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:06:43.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:06:44.462+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:06:44.461+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:06:44.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 4.622 seconds
[2024-11-20T06:07:15.317+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:07:15.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:07:15.321+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:07:15.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:07:16.587+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:07:16.658+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:07:16.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:07:16.712+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:07:16.711+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:07:16.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.451 seconds
[2024-11-20T06:08:51.516+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:08:51.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:08:51.563+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:08:51.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:08:56.615+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:08:56.728+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:08:56.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:08:56.804+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:08:56.804+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:08:56.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 4.095 seconds
[2024-11-20T06:09:27.751+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:09:27.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:09:27.759+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:09:27.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:09:29.105+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:09:29.629+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:09:29.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:09:29.907+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:09:29.892+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:09:30.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.325 seconds
[2024-11-20T06:13:36.314+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:13:37.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:13:37.155+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:13:37.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:13:39.281+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:13:39.339+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:13:39.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:13:39.423+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:13:39.423+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:13:39.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.480 seconds
[2024-11-20T06:14:09.998+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:14:10.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:14:10.008+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:14:10.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:14:11.183+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:14:11.384+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:14:11.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:14:11.437+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:14:11.437+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:14:11.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.500 seconds
[2024-11-20T06:14:41.647+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:14:41.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:14:41.651+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:14:41.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:14:43.253+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:14:43.332+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:14:43.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:14:43.375+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:14:43.374+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:14:43.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.882 seconds
[2024-11-20T06:15:14.690+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:15:14.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:15:14.743+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:15:14.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:15:28.333+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:15:28.455+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:15:28.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:15:28.496+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:15:28.496+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:15:28.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 13.356 seconds
[2024-11-20T06:15:58.927+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:15:58.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:15:58.933+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:15:58.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:15:59.971+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:16:00.096+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:16:00.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:16:00.140+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:16:00.139+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:16:00.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.258 seconds
[2024-11-20T06:16:31.108+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:16:31.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:16:31.114+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:16:31.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:16:32.382+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:16:32.492+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:16:32.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:16:32.555+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:16:32.555+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:16:32.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.497 seconds
[2024-11-20T06:17:02.848+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:17:02.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:17:02.857+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:17:02.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:17:03.895+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:17:04.000+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:17:03.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:17:04.050+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:17:04.049+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:17:04.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.262 seconds
[2024-11-20T06:17:34.554+0000] {processor.py:186} INFO - Started process (PID=281) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:17:34.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:17:34.561+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:17:34.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:17:35.668+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:17:35.786+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:17:35.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:17:35.844+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:17:35.843+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:17:35.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.363 seconds
[2024-11-20T06:18:06.113+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:18:06.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:18:06.117+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:18:06.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:18:07.272+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:18:07.338+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:18:07.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:18:07.378+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:18:07.378+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:18:07.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.306 seconds
[2024-11-20T06:18:39.145+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:18:39.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:18:39.351+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:18:39.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:18:59.168+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:18:59.840+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:18:59.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:18:59.936+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:18:59.936+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:19:00.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 20.276 seconds
[2024-11-20T06:19:26.055+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:19:26.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:19:26.059+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:19:26.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:19:27.264+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:19:27.318+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:19:27.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:19:27.350+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:19:27.350+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:19:27.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.343 seconds
[2024-11-20T06:19:54.477+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:19:54.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:19:54.488+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:19:54.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:19:55.787+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:19:55.899+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:19:55.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:19:55.955+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:19:55.954+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:19:55.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.540 seconds
[2024-11-20T06:20:26.164+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:20:26.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:20:26.175+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:20:26.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:20:27.568+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:20:28.073+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:20:28.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:20:28.142+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:20:28.142+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:20:28.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.060 seconds
[2024-11-20T06:20:49.471+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:20:49.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:20:49.483+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:20:49.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:20:51.834+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:20:51.924+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:20:51.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:20:51.987+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:20:51.986+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:20:52.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.631 seconds
[2024-11-20T06:21:22.366+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:21:22.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:21:22.371+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:21:22.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:21:23.705+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:21:23.838+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:21:23.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:21:23.897+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:21:23.897+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:21:23.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.596 seconds
[2024-11-20T06:21:42.979+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:21:43.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:21:43.106+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:21:43.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:21:48.817+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:21:48.920+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:21:48.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:21:48.962+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:21:48.962+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:21:48.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 5.777 seconds
[2024-11-20T06:22:19.942+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:22:19.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:22:19.947+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:22:19.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:22:21.833+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:22:21.998+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:22:21.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:22:22.061+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:22:22.060+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:22:22.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.201 seconds
[2024-11-20T06:22:52.460+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:22:52.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:22:52.466+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:22:52.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:22:53.483+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:22:53.545+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:22:53.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:22:53.579+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:22:53.579+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:22:53.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.163 seconds
[2024-11-20T06:23:24.277+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:23:24.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:23:24.284+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:23:24.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:24:16.830+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:24:16.783+0000] {timeout.py:68} ERROR - Process timed out, PID: 356
[2024-11-20T06:24:47.091+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:24:47.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:24:47.095+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:24:47.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:24:48.306+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:24:48.365+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:24:48.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:24:48.422+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:24:48.421+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:24:48.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.392 seconds
[2024-11-20T06:25:19.790+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:25:19.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:25:19.801+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:25:19.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:25:25.364+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:26:04.894+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-11-20T06:26:58.430+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:26:58.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:26:58.441+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:26:58.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:27:02.057+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:27:02.545+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:27:02.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:27:04.210+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:27:04.209+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:27:04.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 4.543 seconds
[2024-11-20T06:27:34.500+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:27:34.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:27:34.505+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:27:34.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:27:35.592+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:27:35.729+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:27:35.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:27:35.778+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:27:35.778+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:27:35.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.328 seconds
[2024-11-20T06:28:06.309+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:28:06.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:28:06.313+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:28:06.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:28:06.868+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:28:06.902+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:28:06.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:28:06.944+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:28:06.943+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:28:06.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.677 seconds
[2024-11-20T06:28:37.373+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:28:37.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:28:37.377+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:28:37.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:28:38.290+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:28:38.366+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:28:38.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:28:38.402+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:28:38.401+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:28:38.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.095 seconds
[2024-11-20T06:29:19.636+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:29:24.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:29:24.707+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:29:24.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:29:28.281+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:29:28.330+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:29:28.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:29:28.365+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:29:28.365+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:29:28.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 18.315 seconds
[2024-11-20T06:29:58.563+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:29:58.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:29:58.567+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:29:58.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:30:00.126+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:30:00.274+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:30:00.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:30:00.323+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:30:00.322+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:30:00.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.819 seconds
[2024-11-20T06:30:31.581+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:30:31.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:30:31.624+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:30:31.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:32:00.742+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:32:00.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:32:00.747+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:32:00.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:32:02.487+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:32:02.579+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:32:02.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:32:02.616+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:32:02.616+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:32:02.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.249 seconds
[2024-11-20T06:32:32.828+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:32:32.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:32:32.833+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:32:32.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:32:58.308+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:32:59.693+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:32:59.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:32:59.767+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:32:59.766+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:32:59.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 24.589 seconds
[2024-11-20T06:33:31.228+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:33:31.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:33:31.234+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:33:31.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:33:32.556+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:33:32.685+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:33:32.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:33:32.742+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:33:32.742+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:33:32.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.569 seconds
[2024-11-20T06:34:03.836+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:34:03.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:34:03.840+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:34:03.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:34:04.960+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:34:05.023+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:34:05.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:34:05.067+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:34:05.066+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:34:05.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.274 seconds
[2024-11-20T06:34:36.717+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:34:36.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:34:36.749+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:34:36.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:35:15.703+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:35:15.703+0000] {timeout.py:68} ERROR - Process timed out, PID: 462
[2024-11-20T06:35:15.728+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:35:15.704+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 23, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 645, in parent
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 462
[2024-11-20T06:35:15.729+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:35:16.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 38.317 seconds
[2024-11-20T06:35:47.990+0000] {processor.py:186} INFO - Started process (PID=470) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:35:47.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:35:47.994+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:35:47.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:35:49.211+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:35:50.012+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:35:50.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:35:50.049+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:35:50.048+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:35:50.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.113 seconds
[2024-11-20T06:36:20.782+0000] {processor.py:186} INFO - Started process (PID=485) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:36:20.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:36:20.788+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:36:20.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:36:21.498+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:36:21.532+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:36:21.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:36:21.565+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:36:21.565+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:36:21.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.822 seconds
[2024-11-20T06:36:52.509+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:36:52.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:36:52.514+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:36:52.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:36:53.095+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:36:53.126+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:36:53.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:36:53.157+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:36:53.156+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:36:53.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.707 seconds
[2024-11-20T06:37:24.058+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:37:24.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:37:24.062+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:37:24.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:37:24.740+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:37:24.775+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:37:24.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:37:24.810+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:37:24.810+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:37:24.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.801 seconds
[2024-11-20T06:37:54.978+0000] {processor.py:186} INFO - Started process (PID=509) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:37:54.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:37:54.982+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:37:54.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:37:55.756+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:37:55.787+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:37:55.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:37:55.828+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:37:55.828+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:37:55.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.891 seconds
[2024-11-20T06:38:26.424+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:38:26.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:38:26.427+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:38:26.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:38:27.112+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:38:27.148+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:38:27.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:38:27.188+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:38:27.187+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:38:27.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.821 seconds
[2024-11-20T06:38:57.408+0000] {processor.py:186} INFO - Started process (PID=519) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:38:57.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:38:57.412+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:38:57.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:38:57.986+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:38:58.028+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:38:58.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:38:58.065+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:38:58.065+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:38:58.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.695 seconds
[2024-11-20T06:39:28.813+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:39:28.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:39:28.816+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:39:28.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:39:29.542+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:39:29.573+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:39:29.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:39:29.604+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:39:29.604+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:39:29.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.835 seconds
[2024-11-20T06:40:00.496+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:40:00.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:40:00.500+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:40:00.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:40:01.185+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:40:01.221+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:40:01.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:40:01.264+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:40:01.264+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:40:01.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.822 seconds
[2024-11-20T06:40:32.105+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:40:32.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:40:32.109+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:40:32.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:40:32.874+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:40:32.920+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:40:32.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:40:32.959+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:40:32.958+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:40:32.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.899 seconds
[2024-11-20T06:41:03.079+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:41:03.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:41:03.083+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:41:03.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:41:03.796+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:41:03.862+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:41:03.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:41:03.915+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:41:03.915+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:41:03.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.871 seconds
[2024-11-20T06:41:34.629+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:41:34.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:41:34.633+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:41:34.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:41:35.158+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:41:35.188+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:41:35.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:41:35.218+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:41:35.218+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:41:35.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.626 seconds
[2024-11-20T06:42:05.452+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:42:05.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:42:05.457+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:42:05.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:42:06.088+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:42:06.125+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:42:06.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:42:06.162+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:42:06.162+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:42:06.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.757 seconds
[2024-11-20T06:42:36.783+0000] {processor.py:186} INFO - Started process (PID=572) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:42:36.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:42:36.787+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:42:36.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:42:37.363+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:42:37.405+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:42:37.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:42:37.443+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:42:37.443+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:42:37.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.703 seconds
[2024-11-20T06:43:07.790+0000] {processor.py:186} INFO - Started process (PID=580) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:43:07.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:43:07.794+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:43:07.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:43:08.325+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:43:08.355+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:43:08.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:43:08.389+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:43:08.388+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:43:08.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.642 seconds
[2024-11-20T06:43:39.089+0000] {processor.py:186} INFO - Started process (PID=589) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:43:39.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:43:39.093+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:43:39.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:43:39.556+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:43:39.587+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:43:39.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:43:39.619+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:43:39.619+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:43:39.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.568 seconds
[2024-11-20T06:44:10.935+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:44:10.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:44:10.939+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:44:10.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:44:11.404+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:44:11.437+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:44:11.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:44:11.470+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:44:11.469+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:44:11.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.579 seconds
[2024-11-20T06:44:42.175+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:44:42.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:44:42.179+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:44:42.179+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:44:42.705+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:44:42.737+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:44:42.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:44:42.768+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:44:42.768+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:44:42.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.630 seconds
[2024-11-20T06:45:13.621+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:45:13.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:45:13.624+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:45:13.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:45:14.073+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:45:14.105+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:45:14.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:45:14.136+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:45:14.136+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:45:14.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.552 seconds
[2024-11-20T06:45:44.886+0000] {processor.py:186} INFO - Started process (PID=620) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:45:44.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:45:44.893+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:45:44.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:45:45.599+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:45:45.642+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:45:45.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:45:45.685+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:45:45.684+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:45:45.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.857 seconds
[2024-11-20T06:46:16.510+0000] {processor.py:186} INFO - Started process (PID=628) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:46:16.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:46:16.514+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:46:16.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:46:17.014+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:46:17.046+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:46:17.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:46:17.082+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:46:17.081+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:46:17.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.607 seconds
[2024-11-20T06:46:42.578+0000] {processor.py:186} INFO - Started process (PID=636) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:46:42.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:46:42.581+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:46:42.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:46:43.072+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:46:43.103+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:46:43.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:46:43.156+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:46:43.156+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:46:43.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.624 seconds
[2024-11-20T06:47:13.740+0000] {processor.py:186} INFO - Started process (PID=644) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:47:13.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:47:13.746+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:47:13.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:47:14.223+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:47:14.256+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:47:14.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:47:14.287+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:47:14.287+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:47:14.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.587 seconds
[2024-11-20T06:47:44.785+0000] {processor.py:186} INFO - Started process (PID=652) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:47:44.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:47:44.790+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:47:44.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:47:45.244+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:47:45.278+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:47:45.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:47:45.313+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:47:45.313+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:47:45.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.566 seconds
[2024-11-20T06:48:15.824+0000] {processor.py:186} INFO - Started process (PID=660) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:48:15.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:48:15.829+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:48:15.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:48:16.314+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:48:16.345+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:48:16.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:48:16.382+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:48:16.382+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:48:16.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.599 seconds
[2024-11-20T06:48:46.813+0000] {processor.py:186} INFO - Started process (PID=668) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:48:46.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:48:46.817+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:48:46.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:48:47.289+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:48:47.319+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:48:47.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:48:47.352+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:48:47.352+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:48:47.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.576 seconds
[2024-11-20T06:49:17.997+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:49:17.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:49:18.001+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:49:18.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:49:18.559+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:49:18.594+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:49:18.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:49:18.637+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:49:18.636+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:49:18.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.680 seconds
[2024-11-20T06:49:48.948+0000] {processor.py:186} INFO - Started process (PID=684) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:49:48.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:49:48.952+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:49:48.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:49:49.416+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:49:49.449+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:49:49.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:49:49.481+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:49:49.481+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:49:49.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.569 seconds
[2024-11-20T06:50:20.214+0000] {processor.py:186} INFO - Started process (PID=692) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:50:20.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:50:20.219+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:50:20.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:50:20.731+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:50:20.780+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:50:20.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:50:20.822+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:50:20.822+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:50:20.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.644 seconds
[2024-11-20T06:50:51.004+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:50:51.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:50:51.008+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:50:51.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:50:51.467+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:50:51.500+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:50:51.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:50:51.531+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:50:51.530+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:50:51.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.574 seconds
[2024-11-20T06:51:22.345+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:51:22.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:51:22.350+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:51:22.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:51:22.834+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:51:22.866+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:51:22.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:51:22.897+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:51:22.897+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:51:22.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.600 seconds
[2024-11-20T06:51:53.088+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:51:53.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:51:53.092+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:51:53.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:51:53.560+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:51:53.594+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:51:53.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:51:53.630+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:51:53.629+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:51:53.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.577 seconds
[2024-11-20T06:52:23.758+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:52:23.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:52:23.762+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:52:23.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:52:24.225+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:52:24.261+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:52:24.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:52:24.296+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:52:24.296+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:52:24.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.585 seconds
[2024-11-20T06:52:54.522+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:52:54.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:52:54.527+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:52:54.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:52:55.089+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:52:55.136+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:52:55.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:52:55.174+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:52:55.174+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:52:55.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.696 seconds
[2024-11-20T06:53:25.899+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:53:25.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:53:25.903+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:53:25.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:53:26.388+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:53:26.418+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:53:26.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:53:26.452+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:53:26.451+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:53:26.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.598 seconds
[2024-11-20T06:53:56.722+0000] {processor.py:186} INFO - Started process (PID=749) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:53:56.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:53:56.727+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:53:56.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:53:57.316+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:53:57.360+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:53:57.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:53:57.404+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:53:57.404+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:53:57.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.728 seconds
[2024-11-20T06:54:28.005+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:54:28.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:54:28.009+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:54:28.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:54:28.488+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:54:28.519+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:54:28.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:54:28.550+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:54:28.550+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:54:28.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.584 seconds
[2024-11-20T06:54:58.973+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:54:58.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:54:58.976+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:54:58.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:54:59.420+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:54:59.451+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:54:59.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:54:59.484+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:54:59.483+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:54:59.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.547 seconds
[2024-11-20T06:55:30.153+0000] {processor.py:186} INFO - Started process (PID=774) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:55:30.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:55:30.158+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:55:30.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:55:30.609+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:55:30.644+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:55:30.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:55:30.684+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:55:30.684+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:55:30.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.568 seconds
[2024-11-20T06:56:00.965+0000] {processor.py:186} INFO - Started process (PID=782) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:56:00.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:56:00.969+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:56:00.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:56:01.785+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:56:01.822+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:56:01.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:56:01.855+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:56:01.855+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:56:01.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.930 seconds
[2024-11-20T06:56:32.277+0000] {processor.py:186} INFO - Started process (PID=790) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:56:32.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:56:32.281+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:56:32.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:56:32.922+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:56:32.960+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:56:32.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:56:33.001+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:56:33.001+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:56:33.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.764 seconds
[2024-11-20T06:57:03.543+0000] {processor.py:186} INFO - Started process (PID=798) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:57:03.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:57:03.548+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:57:03.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:57:04.032+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:57:04.062+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:57:04.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:57:04.093+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:57:04.093+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:57:04.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.588 seconds
[2024-11-20T06:57:34.544+0000] {processor.py:186} INFO - Started process (PID=806) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:57:34.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:57:34.548+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:57:34.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:57:35.214+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:57:35.254+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:57:35.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:57:35.301+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:57:35.301+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:57:35.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.094 seconds
[2024-11-20T06:58:06.353+0000] {processor.py:186} INFO - Started process (PID=815) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:58:06.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:58:06.357+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:58:06.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:58:06.951+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:58:06.982+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:58:06.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:58:07.014+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:58:07.014+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:58:07.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.706 seconds
[2024-11-20T06:58:37.186+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:58:37.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:58:37.190+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:58:37.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:58:37.765+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:58:37.799+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:58:37.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:58:37.833+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:58:37.833+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:58:37.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.692 seconds
[2024-11-20T06:59:08.631+0000] {processor.py:186} INFO - Started process (PID=832) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:59:08.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:59:08.635+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:59:08.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:59:09.127+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:59:09.158+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:59:09.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:59:09.191+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:59:09.190+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:59:09.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.609 seconds
[2024-11-20T06:59:39.424+0000] {processor.py:186} INFO - Started process (PID=840) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:59:39.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T06:59:39.428+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:59:39.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:59:40.091+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T06:59:40.154+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:59:40.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T06:59:40.197+0000] {logging_mixin.py:190} INFO - [2024-11-20T06:59:40.197+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T06:59:40.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.824 seconds
[2024-11-20T07:00:10.867+0000] {processor.py:186} INFO - Started process (PID=849) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:00:10.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:00:10.871+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:00:10.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:00:11.393+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:00:11.425+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:00:11.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:00:11.455+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:00:11.455+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:00:11.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.634 seconds
[2024-11-20T07:00:41.654+0000] {processor.py:186} INFO - Started process (PID=858) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:00:41.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:00:41.658+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:00:41.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:00:42.266+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:00:42.303+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:00:42.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:00:42.342+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:00:42.342+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:00:42.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.028 seconds
[2024-11-20T07:01:12.758+0000] {processor.py:186} INFO - Started process (PID=866) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:01:12.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:01:12.765+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:01:12.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:01:13.394+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:01:13.453+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:01:13.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:01:13.506+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:01:13.506+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:01:13.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.797 seconds
[2024-11-20T07:01:44.465+0000] {processor.py:186} INFO - Started process (PID=874) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:01:44.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:01:44.470+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:01:44.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:01:45.033+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:01:45.081+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:01:45.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:01:45.124+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:01:45.124+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:01:45.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.707 seconds
[2024-11-20T07:02:15.289+0000] {processor.py:186} INFO - Started process (PID=882) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:02:15.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:02:15.293+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:02:15.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:02:15.793+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:02:15.826+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:02:15.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:02:15.858+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:02:15.858+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:02:15.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.615 seconds
[2024-11-20T07:02:46.093+0000] {processor.py:186} INFO - Started process (PID=890) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:02:46.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:02:46.097+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:02:46.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:02:46.605+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:02:46.637+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:02:46.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:02:46.668+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:02:46.667+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:02:46.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.630 seconds
[2024-11-20T07:03:17.517+0000] {processor.py:186} INFO - Started process (PID=897) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:03:17.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:03:17.521+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:03:17.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:03:18.197+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:03:18.239+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:03:18.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:03:18.279+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:03:18.279+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:03:18.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.818 seconds
[2024-11-20T07:03:49.189+0000] {processor.py:186} INFO - Started process (PID=905) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:03:49.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:03:49.193+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:03:49.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:03:49.724+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:03:49.762+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:03:49.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:03:49.798+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:03:49.798+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:03:49.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.648 seconds
[2024-11-20T07:04:20.111+0000] {processor.py:186} INFO - Started process (PID=912) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:04:20.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:04:20.115+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:04:20.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:04:20.590+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:04:20.624+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:04:20.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:04:20.656+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:04:20.656+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:04:20.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.590 seconds
[2024-11-20T07:04:51.477+0000] {processor.py:186} INFO - Started process (PID=920) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:04:51.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:04:51.481+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:04:51.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:04:52.097+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:04:52.149+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:04:52.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:04:52.196+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:04:52.196+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:04:52.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.764 seconds
[2024-11-20T07:05:23.016+0000] {processor.py:186} INFO - Started process (PID=928) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:05:23.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:05:23.020+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:05:23.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:05:23.517+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:05:23.548+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:05:23.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:05:23.579+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:05:23.578+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:05:23.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.599 seconds
[2024-11-20T07:05:54.015+0000] {processor.py:186} INFO - Started process (PID=935) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:05:54.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:05:54.019+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:05:54.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:05:54.506+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:05:54.536+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:05:54.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:05:54.567+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:05:54.566+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:05:54.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.601 seconds
[2024-11-20T07:06:25.220+0000] {processor.py:186} INFO - Started process (PID=943) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:06:25.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:06:25.224+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:06:25.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:06:25.689+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:06:25.721+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:06:25.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:06:25.752+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:06:25.752+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:06:26.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.812 seconds
[2024-11-20T07:06:56.242+0000] {processor.py:186} INFO - Started process (PID=951) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:06:56.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:06:56.245+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:06:56.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:06:56.907+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:06:56.947+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:06:56.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:06:56.988+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:06:56.987+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:06:57.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.794 seconds
[2024-11-20T07:07:27.675+0000] {processor.py:186} INFO - Started process (PID=959) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:07:27.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:07:27.678+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:07:27.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:07:28.218+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:07:28.250+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:07:28.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:07:28.284+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:07:28.284+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:07:28.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.654 seconds
[2024-11-20T07:07:58.584+0000] {processor.py:186} INFO - Started process (PID=967) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:07:58.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:07:58.588+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:07:58.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:07:59.121+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:07:59.154+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:07:59.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:07:59.187+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:07:59.186+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:07:59.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.650 seconds
[2024-11-20T07:08:29.858+0000] {processor.py:186} INFO - Started process (PID=976) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:08:29.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:08:29.862+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:08:29.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:08:30.511+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:08:30.551+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:08:30.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:08:30.594+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:08:30.594+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:08:30.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.787 seconds
[2024-11-20T07:09:00.705+0000] {processor.py:186} INFO - Started process (PID=984) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:09:00.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:09:00.709+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:09:00.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:09:01.198+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:09:01.233+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:09:01.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:09:01.264+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:09:01.263+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:09:01.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.596 seconds
[2024-11-20T07:09:31.445+0000] {processor.py:186} INFO - Started process (PID=992) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:09:31.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:09:31.449+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:09:31.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:09:31.904+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:09:31.936+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:09:31.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:09:31.969+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:09:31.968+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:09:32.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.793 seconds
[2024-11-20T07:10:02.960+0000] {processor.py:186} INFO - Started process (PID=1000) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:10:02.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:10:02.964+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:10:02.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:10:03.647+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:10:03.698+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:10:03.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:10:03.740+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:10:03.740+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:10:03.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.822 seconds
[2024-11-20T07:10:34.671+0000] {processor.py:186} INFO - Started process (PID=1008) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:10:34.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:10:34.675+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:10:34.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:10:35.153+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:10:35.186+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:10:35.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:10:35.219+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:10:35.218+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:10:35.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.593 seconds
[2024-11-20T07:11:05.579+0000] {processor.py:186} INFO - Started process (PID=1016) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:11:05.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:11:05.582+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:11:05.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:11:06.126+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:11:06.159+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:11:06.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:11:06.189+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:11:06.188+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:11:06.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.669 seconds
[2024-11-20T07:11:36.887+0000] {processor.py:186} INFO - Started process (PID=1023) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:11:36.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:11:36.891+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:11:36.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:11:37.415+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:11:37.446+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:11:37.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:11:37.476+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:11:37.476+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:11:37.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.627 seconds
[2024-11-20T07:12:08.049+0000] {processor.py:186} INFO - Started process (PID=1031) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:12:08.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:12:08.052+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:12:08.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:12:08.533+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:12:08.564+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:12:08.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:12:08.595+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:12:08.595+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:12:08.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.596 seconds
[2024-11-20T07:12:39.093+0000] {processor.py:186} INFO - Started process (PID=1039) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:12:39.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:12:39.097+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:12:39.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:12:39.577+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:12:39.613+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:12:39.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:12:39.645+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:12:39.645+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:12:39.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.830 seconds
[2024-11-20T07:13:10.006+0000] {processor.py:186} INFO - Started process (PID=1046) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:13:10.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:13:10.010+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:13:10.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:13:10.528+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:13:10.563+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:13:10.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:13:10.598+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:13:10.597+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:13:10.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.639 seconds
[2024-11-20T07:13:40.774+0000] {processor.py:186} INFO - Started process (PID=1054) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:13:40.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:13:40.779+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:13:40.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:13:41.362+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:13:41.412+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:13:41.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:13:41.457+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:13:41.457+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:13:41.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.729 seconds
[2024-11-20T07:14:12.337+0000] {processor.py:186} INFO - Started process (PID=1062) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:14:12.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:14:12.341+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:14:12.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:14:12.853+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:14:12.886+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:14:12.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:14:12.918+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:14:12.918+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:14:12.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.632 seconds
[2024-11-20T07:14:43.104+0000] {processor.py:186} INFO - Started process (PID=1070) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:14:43.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:14:43.108+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:14:43.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:14:43.564+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:14:43.596+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:14:43.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:14:43.627+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:14:43.627+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:14:43.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.676 seconds
[2024-11-20T07:15:14.505+0000] {processor.py:186} INFO - Started process (PID=1078) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:15:14.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:15:14.509+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:15:14.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:15:15.000+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:15:15.031+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:15:15.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:15:15.062+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:15:15.061+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:15:15.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.847 seconds
[2024-11-20T07:15:46.192+0000] {processor.py:186} INFO - Started process (PID=1085) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:15:46.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:15:46.196+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:15:46.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:15:46.669+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:15:46.699+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:15:46.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:15:46.948+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:15:46.947+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:15:46.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.800 seconds
[2024-11-20T07:16:17.847+0000] {processor.py:186} INFO - Started process (PID=1093) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:16:17.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:16:17.852+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:16:17.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:16:18.475+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:16:18.517+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:16:18.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:16:18.561+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:16:18.561+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:16:18.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.767 seconds
[2024-11-20T07:16:48.819+0000] {processor.py:186} INFO - Started process (PID=1101) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:16:48.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:16:48.823+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:16:48.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:16:49.292+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:16:49.325+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:16:49.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:16:49.356+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:16:49.355+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:16:49.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.584 seconds
[2024-11-20T07:17:19.563+0000] {processor.py:186} INFO - Started process (PID=1109) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:17:19.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:17:19.568+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:17:19.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:17:20.189+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:17:20.233+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:17:20.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:17:20.272+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:17:20.272+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:17:20.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.763 seconds
[2024-11-20T07:17:51.134+0000] {processor.py:186} INFO - Started process (PID=1117) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:17:51.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:17:51.139+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:17:51.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:17:51.679+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:17:51.714+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:17:51.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:17:51.745+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:17:51.745+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:17:51.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.660 seconds
[2024-11-20T07:18:21.927+0000] {processor.py:186} INFO - Started process (PID=1125) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:18:21.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:18:21.931+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:18:21.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:18:22.388+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:18:22.420+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:18:22.419+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:18:22.462+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:18:22.462+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:18:22.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.789 seconds
[2024-11-20T07:18:53.664+0000] {processor.py:186} INFO - Started process (PID=1133) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:18:53.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:18:53.668+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:18:53.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:18:54.149+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:18:54.179+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:18:54.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:18:54.212+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:18:54.211+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:18:54.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.593 seconds
[2024-11-20T07:19:24.839+0000] {processor.py:186} INFO - Started process (PID=1141) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:19:24.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:19:24.843+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:19:24.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:19:25.331+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:19:25.371+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:19:25.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:19:25.404+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:19:25.404+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:19:25.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.621 seconds
[2024-11-20T07:19:56.118+0000] {processor.py:186} INFO - Started process (PID=1148) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:19:56.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:19:56.125+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:19:56.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:19:56.826+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:19:56.874+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:19:56.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:19:56.913+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:19:56.913+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:19:56.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.846 seconds
[2024-11-20T07:20:27.052+0000] {processor.py:186} INFO - Started process (PID=1156) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:20:27.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:20:27.055+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:20:27.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:20:27.526+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:20:27.557+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:20:27.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:20:27.589+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:20:27.589+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:20:27.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.576 seconds
[2024-11-20T07:20:57.864+0000] {processor.py:186} INFO - Started process (PID=1158) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:20:57.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:20:57.869+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:20:57.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:20:58.433+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:20:58.504+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:20:58.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:20:58.571+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:20:58.571+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:20:58.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.786 seconds
[2024-11-20T07:21:29.172+0000] {processor.py:186} INFO - Started process (PID=1166) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:21:29.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:21:29.175+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:21:29.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:21:29.744+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:21:29.780+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:21:29.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:21:29.813+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:21:29.813+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:21:30.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.902 seconds
[2024-11-20T07:22:00.236+0000] {processor.py:186} INFO - Started process (PID=1175) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:22:00.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:22:00.241+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:22:00.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:22:00.829+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:22:00.869+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:22:00.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:22:00.905+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:22:00.905+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:22:00.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.724 seconds
[2024-11-20T07:22:31.754+0000] {processor.py:186} INFO - Started process (PID=1182) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:22:31.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:22:31.758+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:22:31.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:22:32.368+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:22:32.402+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:22:32.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:22:32.435+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:22:32.435+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:22:32.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.731 seconds
[2024-11-20T07:23:02.584+0000] {processor.py:186} INFO - Started process (PID=1190) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:23:02.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:23:02.588+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:23:02.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:23:03.116+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:23:03.149+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:23:03.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:23:03.181+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:23:03.181+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:23:03.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.634 seconds
[2024-11-20T07:23:33.350+0000] {processor.py:186} INFO - Started process (PID=1198) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:23:33.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:23:33.357+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:23:33.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:23:34.010+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:23:34.061+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:23:34.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:23:34.106+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:23:34.106+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:23:34.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.805 seconds
[2024-11-20T07:24:04.891+0000] {processor.py:186} INFO - Started process (PID=1206) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:24:04.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:24:04.894+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:24:04.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:24:05.371+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:24:05.402+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:24:05.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:24:05.432+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:24:05.432+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:24:05.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.792 seconds
[2024-11-20T07:24:36.566+0000] {processor.py:186} INFO - Started process (PID=1213) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:24:36.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:24:36.570+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:24:36.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:24:37.149+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:24:37.198+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:24:37.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:24:37.520+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:24:37.519+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:24:37.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.997 seconds
[2024-11-20T07:25:08.398+0000] {processor.py:186} INFO - Started process (PID=1221) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:25:08.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:25:08.402+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:25:08.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:25:09.017+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:25:09.048+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:25:09.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:25:09.080+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:25:09.080+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:25:09.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.730 seconds
[2024-11-20T07:25:39.199+0000] {processor.py:186} INFO - Started process (PID=1229) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:25:39.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:25:39.203+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:25:39.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:25:39.899+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:25:39.943+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:25:39.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:25:39.974+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:25:39.974+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:25:40.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.831 seconds
[2024-11-20T07:26:10.758+0000] {processor.py:186} INFO - Started process (PID=1238) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:26:10.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:26:10.762+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:26:10.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:26:11.387+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:26:11.417+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:26:11.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:26:11.457+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:26:11.456+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:26:11.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.736 seconds
[2024-11-20T07:26:41.542+0000] {processor.py:186} INFO - Started process (PID=1246) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:26:41.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:26:41.546+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:26:41.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:26:42.098+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:26:42.133+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:26:42.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:26:42.165+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:26:42.164+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:26:42.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.668 seconds
[2024-11-20T07:27:12.386+0000] {processor.py:186} INFO - Started process (PID=1255) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:27:12.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:27:12.390+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:27:12.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:27:12.975+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:27:13.015+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:27:13.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:27:13.062+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:27:13.062+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:27:13.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.016 seconds
[2024-11-20T07:27:44.198+0000] {processor.py:186} INFO - Started process (PID=1263) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:27:44.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:27:44.202+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:27:44.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:27:44.862+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:27:44.916+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:27:44.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:27:45.230+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:27:45.229+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:27:45.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.074 seconds
[2024-11-20T07:28:15.999+0000] {processor.py:186} INFO - Started process (PID=1270) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:28:16.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:28:16.003+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:28:16.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:28:16.705+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:28:16.739+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:28:16.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:28:16.770+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:28:16.770+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:28:16.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.818 seconds
[2024-11-20T07:28:47.645+0000] {processor.py:186} INFO - Started process (PID=1279) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:28:47.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:28:47.648+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:28:47.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:28:48.273+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:28:48.306+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:28:48.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:28:48.337+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:28:48.337+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:28:48.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.752 seconds
[2024-11-20T07:29:18.623+0000] {processor.py:186} INFO - Started process (PID=1287) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:29:18.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:29:18.627+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:29:18.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:29:19.146+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:29:19.178+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:29:19.177+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:29:19.212+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:29:19.212+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:29:19.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.626 seconds
[2024-11-20T07:29:50.018+0000] {processor.py:186} INFO - Started process (PID=1295) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:29:50.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:29:50.022+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:29:50.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:29:50.530+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:29:50.563+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:29:50.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:29:50.595+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:29:50.595+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:29:50.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.623 seconds
[2024-11-20T07:30:20.830+0000] {processor.py:186} INFO - Started process (PID=1303) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:30:20.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:30:20.834+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:30:20.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:30:21.423+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:30:21.467+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:30:21.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:30:21.523+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:30:21.522+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:30:21.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.001 seconds
[2024-11-20T07:30:52.688+0000] {processor.py:186} INFO - Started process (PID=1311) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:30:52.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:30:52.691+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:30:52.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:30:53.351+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:30:53.382+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:30:53.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:30:53.624+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:30:53.623+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:30:53.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.969 seconds
[2024-11-20T07:31:24.574+0000] {processor.py:186} INFO - Started process (PID=1319) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:31:24.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:31:24.578+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:31:24.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:31:25.173+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:31:25.217+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:31:25.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:31:25.259+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:31:25.259+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:31:25.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.724 seconds
[2024-11-20T07:31:56.146+0000] {processor.py:186} INFO - Started process (PID=1327) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:31:56.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:31:56.150+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:31:56.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:31:56.638+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:31:56.669+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:31:56.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:31:56.701+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:31:56.701+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:31:56.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.596 seconds
[2024-11-20T07:32:27.111+0000] {processor.py:186} INFO - Started process (PID=1335) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:32:27.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:32:27.114+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:32:27.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:32:27.673+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:32:27.704+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:32:27.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:32:27.734+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:32:27.734+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:32:27.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.669 seconds
[2024-11-20T07:32:58.357+0000] {processor.py:186} INFO - Started process (PID=1342) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:32:58.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:32:58.360+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:32:58.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:32:58.856+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:32:58.886+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:32:58.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:32:58.919+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:32:58.919+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:32:59.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.831 seconds
[2024-11-20T07:33:29.438+0000] {processor.py:186} INFO - Started process (PID=1350) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:33:29.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:33:29.443+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:33:29.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:33:29.930+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:33:29.965+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:33:29.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:33:30.197+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:33:30.197+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:33:30.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.797 seconds
[2024-11-20T07:34:00.769+0000] {processor.py:186} INFO - Started process (PID=1358) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:34:00.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:34:00.775+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:34:00.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:34:01.406+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:34:01.449+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:34:01.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:34:01.491+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:34:01.491+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:34:01.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.762 seconds
[2024-11-20T07:34:31.823+0000] {processor.py:186} INFO - Started process (PID=1366) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:34:31.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:34:31.827+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:34:31.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:34:32.487+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:34:32.537+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:34:32.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:34:32.597+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:34:32.597+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:34:32.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.818 seconds
[2024-11-20T07:35:03.253+0000] {processor.py:186} INFO - Started process (PID=1373) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:35:03.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:35:03.257+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:35:03.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:35:03.835+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:35:03.873+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:35:03.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:35:03.909+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:35:03.909+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:35:03.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.696 seconds
[2024-11-20T07:35:34.246+0000] {processor.py:186} INFO - Started process (PID=1381) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:35:34.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:35:34.250+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:35:34.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:35:34.739+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:35:34.776+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:35:34.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:35:34.812+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:35:34.812+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:35:34.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.604 seconds
[2024-11-20T07:36:05.585+0000] {processor.py:186} INFO - Started process (PID=1389) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:36:05.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:36:05.589+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:36:05.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:36:06.119+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:36:06.150+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:36:06.149+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:36:06.182+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:36:06.181+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:36:06.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.838 seconds
[2024-11-20T07:36:37.298+0000] {processor.py:186} INFO - Started process (PID=1397) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:36:37.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:36:37.302+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:36:37.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:36:37.767+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:36:37.798+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:36:37.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:36:38.033+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:36:38.033+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:36:38.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.775 seconds
[2024-11-20T07:37:08.180+0000] {processor.py:186} INFO - Started process (PID=1405) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:37:08.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:37:08.185+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:37:08.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:37:08.768+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:37:08.810+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:37:08.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:37:08.852+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:37:08.851+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:37:08.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.725 seconds
[2024-11-20T07:37:39.692+0000] {processor.py:186} INFO - Started process (PID=1414) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:37:39.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:37:39.697+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:37:39.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:37:40.291+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:37:40.333+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:37:40.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:37:40.375+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:37:40.375+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:37:40.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.725 seconds
[2024-11-20T07:38:10.563+0000] {processor.py:186} INFO - Started process (PID=1422) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:38:10.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:38:10.569+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:38:10.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:38:11.160+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:38:11.199+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:38:11.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:38:11.258+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:38:11.248+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:38:11.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.740 seconds
[2024-11-20T07:38:42.128+0000] {processor.py:186} INFO - Started process (PID=1430) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:38:42.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:38:42.133+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:38:42.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:38:42.598+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:38:42.629+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:38:42.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:38:42.660+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:38:42.660+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:38:42.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.787 seconds
[2024-11-20T07:39:13.736+0000] {processor.py:186} INFO - Started process (PID=1438) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:39:13.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:39:13.739+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:39:13.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:39:14.236+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:39:14.268+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:39:14.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:39:14.513+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:39:14.513+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:39:14.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.812 seconds
[2024-11-20T07:39:44.663+0000] {processor.py:186} INFO - Started process (PID=1446) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:39:44.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:39:44.667+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:39:44.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:39:45.120+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:39:45.155+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:39:45.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:39:45.387+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:39:45.387+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:39:45.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.759 seconds
[2024-11-20T07:40:16.230+0000] {processor.py:186} INFO - Started process (PID=1455) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:40:16.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:40:16.233+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:40:16.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:40:16.756+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:40:16.796+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:40:16.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:40:16.828+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:40:16.828+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:40:16.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.641 seconds
[2024-11-20T07:40:47.113+0000] {processor.py:186} INFO - Started process (PID=1462) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:40:47.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:40:47.116+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:40:47.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:40:47.557+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:40:47.592+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:40:47.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:40:47.623+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:40:47.623+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:40:47.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.549 seconds
[2024-11-20T07:41:18.472+0000] {processor.py:186} INFO - Started process (PID=1471) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:41:18.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:41:18.476+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:41:18.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:41:19.082+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:41:19.120+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:41:19.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:41:19.163+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:41:19.163+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:41:19.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.734 seconds
[2024-11-20T07:41:50.131+0000] {processor.py:186} INFO - Started process (PID=1479) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:41:50.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:41:50.137+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:41:50.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:41:50.693+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:41:50.730+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:41:50.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:41:50.771+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:41:50.771+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:41:51.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.919 seconds
[2024-11-20T07:42:21.990+0000] {processor.py:186} INFO - Started process (PID=1487) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:42:21.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:42:21.994+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:42:21.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:42:22.454+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:42:22.485+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:42:22.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:42:22.722+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:42:22.722+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:42:22.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.776 seconds
[2024-11-20T07:42:52.886+0000] {processor.py:186} INFO - Started process (PID=1495) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:42:52.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:42:52.891+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:42:52.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:42:53.350+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:42:53.384+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:42:53.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:42:53.414+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:42:53.414+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:42:53.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.580 seconds
[2024-11-20T07:43:24.292+0000] {processor.py:186} INFO - Started process (PID=1503) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:43:24.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:43:24.296+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:43:24.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:43:24.745+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:43:24.777+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:43:24.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:43:24.807+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:43:24.807+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:43:24.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.561 seconds
[2024-11-20T07:43:55.678+0000] {processor.py:186} INFO - Started process (PID=1511) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:43:55.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:43:55.681+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:43:55.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:43:56.131+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:43:56.164+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:43:56.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:43:56.195+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:43:56.195+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:43:56.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.554 seconds
[2024-11-20T07:44:27.119+0000] {processor.py:186} INFO - Started process (PID=1519) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:44:27.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:44:27.123+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:44:27.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:44:27.561+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:44:27.594+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:44:27.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:44:27.627+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:44:27.626+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:44:27.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.556 seconds
[2024-11-20T07:44:58.560+0000] {processor.py:186} INFO - Started process (PID=1527) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:44:58.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:44:58.564+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:44:58.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:44:59.013+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:44:59.052+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:44:59.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:44:59.084+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:44:59.084+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:44:59.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.764 seconds
[2024-11-20T07:45:30.052+0000] {processor.py:186} INFO - Started process (PID=1536) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:45:30.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:45:30.058+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:45:30.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:45:30.714+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:45:30.764+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:45:30.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:45:31.084+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:45:31.084+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:45:31.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.076 seconds
[2024-11-20T07:46:01.902+0000] {processor.py:186} INFO - Started process (PID=1544) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:46:01.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:46:01.906+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:46:01.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:46:02.408+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:46:02.451+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:46:02.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:46:02.487+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:46:02.487+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:46:02.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.625 seconds
[2024-11-20T07:46:33.397+0000] {processor.py:186} INFO - Started process (PID=1551) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:46:33.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:46:33.401+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:46:33.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:46:33.843+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:46:33.875+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:46:33.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:46:33.905+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:46:33.904+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:46:33.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.544 seconds
[2024-11-20T07:47:04.587+0000] {processor.py:186} INFO - Started process (PID=1558) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:47:04.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:47:04.592+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:47:04.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:47:05.050+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:47:05.081+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:47:05.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:47:05.114+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:47:05.113+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:47:05.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.569 seconds
[2024-11-20T07:47:36.071+0000] {processor.py:186} INFO - Started process (PID=1566) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:47:36.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:47:36.076+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:47:36.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:47:36.562+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:47:36.594+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:47:36.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:47:36.624+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:47:36.624+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:47:36.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.799 seconds
[2024-11-20T07:48:07.405+0000] {processor.py:186} INFO - Started process (PID=1574) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:48:07.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:48:07.409+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:48:07.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:48:07.885+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:48:07.922+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:48:07.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:48:08.189+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:48:08.189+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:48:08.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.818 seconds
[2024-11-20T07:48:39.047+0000] {processor.py:186} INFO - Started process (PID=1582) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:48:39.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:48:39.051+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:48:39.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:48:39.510+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:48:39.542+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:48:39.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:48:39.777+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:48:39.777+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:48:39.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.785 seconds
[2024-11-20T07:49:10.469+0000] {processor.py:186} INFO - Started process (PID=1590) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:49:10.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:49:10.474+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:49:10.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:49:11.126+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:49:11.179+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:49:11.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:49:11.222+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:49:11.221+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:49:11.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.800 seconds
[2024-11-20T07:49:42.135+0000] {processor.py:186} INFO - Started process (PID=1598) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:49:42.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:49:42.139+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:49:42.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:49:42.673+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:49:42.710+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:49:42.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:49:42.745+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:49:42.745+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:49:42.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.659 seconds
[2024-11-20T07:50:13.293+0000] {processor.py:186} INFO - Started process (PID=1606) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:50:13.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:50:13.297+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:50:13.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:50:13.753+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:50:13.785+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:50:13.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:50:13.815+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:50:13.815+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:50:13.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.568 seconds
[2024-11-20T07:50:44.825+0000] {processor.py:186} INFO - Started process (PID=1614) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:50:44.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:50:44.829+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:50:44.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:50:45.279+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:50:45.310+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:50:45.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:50:45.342+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:50:45.342+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:50:45.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.765 seconds
[2024-11-20T07:51:16.354+0000] {processor.py:186} INFO - Started process (PID=1622) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:51:16.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:51:16.360+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:51:16.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:51:16.874+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:51:16.906+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:51:16.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:51:17.157+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:51:17.157+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:51:17.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.850 seconds
[2024-11-20T07:51:48.101+0000] {processor.py:186} INFO - Started process (PID=1631) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:51:48.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:51:48.104+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:51:48.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:51:48.555+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:51:48.587+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:51:48.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T07:51:48.833+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:51:48.833+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T07:51:48.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.776 seconds
[2024-11-20T07:52:19.687+0000] {processor.py:186} INFO - Started process (PID=1639) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T07:52:19.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T07:52:19.702+0000] {logging_mixin.py:190} INFO - [2024-11-20T07:52:19.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:56:11.458+0000] {processor.py:186} INFO - Started process (PID=1647) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:56:11.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T11:56:11.489+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:56:11.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:56:13.788+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:56:19.596+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:56:19.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T11:56:19.712+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:56:19.712+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T11:56:19.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 8.384 seconds
[2024-11-20T11:56:50.453+0000] {processor.py:186} INFO - Started process (PID=1661) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:56:50.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T11:56:50.457+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:56:50.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:56:51.865+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:56:52.084+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:56:52.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T11:56:52.256+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:56:52.255+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T11:56:53.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.764 seconds
[2024-11-20T11:57:24.149+0000] {processor.py:186} INFO - Started process (PID=1669) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:57:24.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T11:57:24.165+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:57:24.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:57:26.247+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:57:26.391+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:57:26.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T11:57:27.286+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:57:27.286+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T11:57:27.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.292 seconds
[2024-11-20T11:57:57.578+0000] {processor.py:186} INFO - Started process (PID=1678) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:57:57.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T11:57:57.583+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:57:57.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:57:58.354+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:57:58.401+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:57:58.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T11:57:58.758+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:57:58.758+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T11:57:58.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.258 seconds
[2024-11-20T11:58:29.407+0000] {processor.py:186} INFO - Started process (PID=1686) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:58:29.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T11:58:29.412+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:58:29.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:58:30.208+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:58:30.258+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:58:30.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T11:58:30.317+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:58:30.316+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T11:58:30.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.983 seconds
[2024-11-20T11:59:01.362+0000] {processor.py:186} INFO - Started process (PID=1694) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:59:01.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T11:59:01.366+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:59:01.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:59:01.937+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:59:01.987+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:59:01.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T11:59:02.022+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:59:02.021+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T11:59:02.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.718 seconds
[2024-11-20T11:59:32.508+0000] {processor.py:186} INFO - Started process (PID=1701) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:59:32.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T11:59:32.513+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:59:32.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:59:33.712+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T11:59:33.748+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:59:33.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T11:59:33.819+0000] {logging_mixin.py:190} INFO - [2024-11-20T11:59:33.818+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T11:59:34.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.832 seconds
[2024-11-20T12:00:04.510+0000] {processor.py:186} INFO - Started process (PID=1709) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:00:04.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:00:04.514+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:00:04.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:00:05.164+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:00:05.210+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:00:05.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:00:06.025+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:00:06.025+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:00:06.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.131 seconds
[2024-11-20T12:00:36.585+0000] {processor.py:186} INFO - Started process (PID=1717) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:00:36.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:00:36.590+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:00:36.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:00:37.274+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:00:37.331+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:00:37.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:00:37.800+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:00:37.799+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:00:37.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.268 seconds
[2024-11-20T12:01:08.689+0000] {processor.py:186} INFO - Started process (PID=1725) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:01:08.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:01:08.694+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:01:08.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:01:09.419+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:01:09.459+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:01:09.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:01:09.514+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:01:09.513+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:01:09.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.879 seconds
[2024-11-20T12:01:40.269+0000] {processor.py:186} INFO - Started process (PID=1733) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:01:40.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:01:40.275+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:01:40.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:01:41.342+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:01:41.392+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:01:41.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:01:41.436+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:01:41.435+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:01:41.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.233 seconds
[2024-11-20T12:02:12.241+0000] {processor.py:186} INFO - Started process (PID=1741) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:02:12.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:02:12.246+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:02:12.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:02:13.232+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:02:13.299+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:02:13.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:02:13.362+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:02:13.362+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:02:13.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.532 seconds
[2024-11-20T12:02:44.127+0000] {processor.py:186} INFO - Started process (PID=1749) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:02:44.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:02:44.132+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:02:44.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:02:45.037+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:02:45.164+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:02:45.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:02:45.612+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:02:45.611+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:02:45.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.546 seconds
[2024-11-20T12:03:16.538+0000] {processor.py:186} INFO - Started process (PID=1757) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:03:16.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:03:16.545+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:03:16.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:03:17.367+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:03:17.428+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:03:17.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:03:18.097+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:03:18.097+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:03:18.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.616 seconds
[2024-11-20T12:03:49.003+0000] {processor.py:186} INFO - Started process (PID=1765) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:03:49.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:03:49.016+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:03:49.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:03:51.155+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:03:51.307+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:03:51.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:03:51.412+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:03:51.411+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:03:51.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.573 seconds
[2024-11-20T12:04:22.182+0000] {processor.py:186} INFO - Started process (PID=1773) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:04:22.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:04:22.190+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:04:22.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:04:23.207+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:04:23.270+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:04:23.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:04:23.341+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:04:23.339+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:04:23.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.232 seconds
[2024-11-20T12:04:53.747+0000] {processor.py:186} INFO - Started process (PID=1781) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:04:53.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:04:53.753+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:04:53.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:04:54.472+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:04:54.537+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:04:54.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:04:54.599+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:04:54.598+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:04:54.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.915 seconds
[2024-11-20T12:05:25.237+0000] {processor.py:186} INFO - Started process (PID=1790) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:05:25.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:05:25.242+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:05:25.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:05:25.910+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:05:25.951+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:05:25.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:05:26.318+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:05:26.317+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:05:26.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.163 seconds
[2024-11-20T12:05:56.892+0000] {processor.py:186} INFO - Started process (PID=1800) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:05:56.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:05:56.897+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:05:56.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:05:57.642+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:05:57.697+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:05:57.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:05:58.102+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:05:58.102+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:05:58.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.283 seconds
[2024-11-20T12:06:28.603+0000] {processor.py:186} INFO - Started process (PID=1813) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:06:28.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:06:28.609+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:06:28.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:06:29.512+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:06:29.558+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:06:29.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:06:29.601+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:06:29.601+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:06:29.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.081 seconds
[2024-11-20T12:07:00.112+0000] {processor.py:186} INFO - Started process (PID=1821) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:07:00.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:07:00.133+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:07:00.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:07:01.318+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:07:01.372+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:07:01.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:07:01.432+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:07:01.432+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:07:01.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.391 seconds
[2024-11-20T12:07:31.735+0000] {processor.py:186} INFO - Started process (PID=1829) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:07:31.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:07:31.739+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:07:31.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:07:32.503+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:07:32.561+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:07:32.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:07:32.606+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:07:32.606+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:07:32.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.944 seconds
[2024-11-20T12:08:03.208+0000] {processor.py:186} INFO - Started process (PID=1837) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:08:03.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:08:03.216+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:08:03.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:08:03.927+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:08:03.977+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:08:03.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:08:04.032+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:08:04.032+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:08:04.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.191 seconds
[2024-11-20T12:08:34.774+0000] {processor.py:186} INFO - Started process (PID=1845) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:08:34.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:08:34.781+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:08:34.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:08:35.701+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:08:35.763+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:08:35.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:08:36.254+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:08:36.253+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:08:36.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.557 seconds
[2024-11-20T12:09:06.962+0000] {processor.py:186} INFO - Started process (PID=1853) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:09:06.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:09:06.965+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:09:06.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:09:07.975+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:09:08.349+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:09:08.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:09:08.390+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:09:08.390+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:09:08.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.481 seconds
[2024-11-20T12:09:38.836+0000] {processor.py:186} INFO - Started process (PID=1861) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:09:38.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:09:38.845+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:09:38.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:09:39.773+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:09:39.834+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:09:39.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:09:39.932+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:09:39.931+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:09:39.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.125 seconds
[2024-11-20T12:10:10.467+0000] {processor.py:186} INFO - Started process (PID=1869) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:10:10.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:10:10.472+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:10:10.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:10:11.404+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:10:11.488+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:10:11.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:10:11.554+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:10:11.553+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:10:11.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.160 seconds
[2024-11-20T12:10:42.163+0000] {processor.py:186} INFO - Started process (PID=1877) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:10:42.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:10:42.168+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:10:42.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:10:43.522+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:10:43.573+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:10:43.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:10:43.640+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:10:43.639+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:10:44.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.249 seconds
[2024-11-20T12:11:14.734+0000] {processor.py:186} INFO - Started process (PID=1886) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:11:14.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:11:14.739+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:11:14.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:11:15.523+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:11:15.573+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:11:15.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:11:15.955+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:11:15.955+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:11:15.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.279 seconds
[2024-11-20T12:11:46.346+0000] {processor.py:186} INFO - Started process (PID=1894) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:11:46.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:11:46.351+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:11:46.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:11:47.160+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:11:47.551+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:11:47.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:11:47.601+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:11:47.601+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:11:47.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.328 seconds
[2024-11-20T12:12:18.142+0000] {processor.py:186} INFO - Started process (PID=1902) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:12:18.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:12:18.155+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:12:18.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:12:19.040+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:12:19.105+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:12:19.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:12:19.192+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:12:19.192+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:12:19.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.127 seconds
[2024-11-20T12:12:49.643+0000] {processor.py:186} INFO - Started process (PID=1910) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:12:49.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:12:49.651+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:12:49.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:12:50.474+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:12:50.537+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:12:50.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:12:50.590+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:12:50.590+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:12:50.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.022 seconds
[2024-11-20T12:13:21.108+0000] {processor.py:186} INFO - Started process (PID=1918) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:13:21.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:13:21.113+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:13:21.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:13:22.161+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:13:22.236+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:13:22.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:13:22.345+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:13:22.344+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:13:23.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.102 seconds
[2024-11-20T12:13:53.587+0000] {processor.py:186} INFO - Started process (PID=1926) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:13:53.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:13:53.594+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:13:53.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:13:54.368+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:13:54.435+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:13:54.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:13:54.931+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:13:54.930+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:13:54.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.399 seconds
[2024-11-20T12:14:25.268+0000] {processor.py:186} INFO - Started process (PID=1934) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:14:25.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:14:25.276+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:14:25.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:14:25.903+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:14:26.206+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:14:26.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:14:26.246+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:14:26.246+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:14:26.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.052 seconds
[2024-11-20T12:14:56.767+0000] {processor.py:186} INFO - Started process (PID=1943) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:14:56.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:14:56.773+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:14:56.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:14:57.558+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:14:57.608+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:14:57.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:14:57.653+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:14:57.652+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:14:57.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.942 seconds
[2024-11-20T12:15:28.238+0000] {processor.py:186} INFO - Started process (PID=1951) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:15:28.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:15:28.242+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:15:28.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:15:29.058+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:15:29.101+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:15:29.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:15:29.159+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:15:29.159+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:15:29.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.014 seconds
[2024-11-20T12:15:59.908+0000] {processor.py:186} INFO - Started process (PID=1965) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:15:59.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:15:59.919+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:15:59.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:16:00.999+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:16:01.091+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:16:01.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:16:01.167+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:16:01.167+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:16:01.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.914 seconds
[2024-11-20T12:16:32.350+0000] {processor.py:186} INFO - Started process (PID=1974) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:16:32.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:16:32.354+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:16:32.353+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:16:33.333+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:16:33.408+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:16:33.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:16:33.835+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:16:33.834+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:16:33.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.542 seconds
[2024-11-20T12:17:04.563+0000] {processor.py:186} INFO - Started process (PID=1982) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:17:04.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:17:04.568+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:17:04.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:17:05.626+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:17:06.164+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:17:06.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:17:06.259+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:17:06.252+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:17:06.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.777 seconds
[2024-11-20T12:17:36.848+0000] {processor.py:186} INFO - Started process (PID=1990) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:17:36.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:17:36.854+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:17:36.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:17:37.683+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:17:37.743+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:17:37.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:17:37.809+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:17:37.809+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:17:37.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.034 seconds
[2024-11-20T12:18:08.292+0000] {processor.py:186} INFO - Started process (PID=1998) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:18:08.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:18:08.302+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:18:08.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:18:09.087+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:18:09.140+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:18:09.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:18:09.194+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:18:09.193+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:18:09.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.958 seconds
[2024-11-20T12:18:39.807+0000] {processor.py:186} INFO - Started process (PID=2006) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:18:39.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:18:39.810+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:18:39.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:18:40.618+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:18:40.668+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:18:40.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:18:40.724+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:18:40.723+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:18:41.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.250 seconds
[2024-11-20T12:19:11.513+0000] {processor.py:186} INFO - Started process (PID=2014) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:19:11.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:19:11.516+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:19:11.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:19:12.335+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:19:12.386+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:19:12.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:19:12.778+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:19:12.778+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:19:12.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.343 seconds
[2024-11-20T12:19:43.038+0000] {processor.py:186} INFO - Started process (PID=2022) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:19:43.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:19:43.050+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:19:43.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:19:44.071+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:19:44.141+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:19:44.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:19:44.693+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:19:44.692+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:19:44.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.718 seconds
[2024-11-20T12:20:14.994+0000] {processor.py:186} INFO - Started process (PID=2030) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:20:14.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:20:15.001+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:20:14.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:20:16.549+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:20:17.260+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:20:17.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:20:17.350+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:20:17.350+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:20:17.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.431 seconds
[2024-11-20T12:20:47.942+0000] {processor.py:186} INFO - Started process (PID=2039) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:20:47.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:20:47.949+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:20:47.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:20:48.647+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:20:48.714+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:20:48.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:20:48.807+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:20:48.806+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:20:48.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.038 seconds
[2024-11-20T12:21:19.666+0000] {processor.py:186} INFO - Started process (PID=2048) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:21:19.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:21:19.673+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:21:19.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:21:20.560+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:21:20.642+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:21:20.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:21:20.727+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:21:20.727+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:21:21.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.002 seconds
[2024-11-20T12:21:52.381+0000] {processor.py:186} INFO - Started process (PID=2056) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:21:52.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:21:52.388+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:21:52.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:21:53.033+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:21:53.077+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:21:53.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:21:53.421+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:21:53.420+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:21:53.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.101 seconds
[2024-11-20T12:22:23.847+0000] {processor.py:186} INFO - Started process (PID=2065) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:22:23.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:22:23.851+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:22:23.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:22:24.654+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:22:24.722+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:22:24.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:22:25.078+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:22:25.078+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:22:25.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.279 seconds
[2024-11-20T12:22:55.452+0000] {processor.py:186} INFO - Started process (PID=2073) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:22:55.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:22:55.456+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:22:55.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:22:56.383+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:22:56.466+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:22:56.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:22:56.534+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:22:56.533+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:22:56.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.159 seconds
[2024-11-20T12:23:27.811+0000] {processor.py:186} INFO - Started process (PID=2081) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:23:27.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:23:27.997+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:23:27.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:23:32.769+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:23:32.930+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:23:32.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:23:33.079+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:23:33.079+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:23:33.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 5.454 seconds
[2024-11-20T12:24:04.014+0000] {processor.py:186} INFO - Started process (PID=2095) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:24:04.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:24:04.020+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:24:04.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:24:05.174+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:24:05.271+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:24:05.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:24:05.384+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:24:05.384+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:24:07.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.733 seconds
[2024-11-20T12:29:18.648+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:29:18.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:29:18.663+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:29:18.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:29:25.584+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:29:25.722+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:29:25.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:29:26.181+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:29:26.179+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:29:26.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 7.744 seconds
[2024-11-20T12:29:57.536+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:29:57.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:29:57.635+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:29:57.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:30:05.731+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:30:06.042+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:30:06.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:30:06.479+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:30:06.478+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:30:06.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 9.597 seconds
[2024-11-20T12:30:37.795+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:30:37.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:30:37.830+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:30:37.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:30:41.537+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:30:41.610+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:30:41.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:30:41.667+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:30:41.667+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:30:41.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.941 seconds
[2024-11-20T12:31:12.687+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:31:12.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:31:12.715+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:31:12.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:31:14.127+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:31:14.233+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:31:14.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:31:14.367+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:31:14.367+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:31:15.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.472 seconds
[2024-11-20T12:31:45.794+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:31:45.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:31:46.052+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:31:46.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:31:48.126+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:31:48.193+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:31:48.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:31:48.260+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:31:48.260+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:31:48.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.605 seconds
[2024-11-20T12:32:19.106+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:32:19.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:32:19.556+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:32:19.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:32:21.927+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:32:22.007+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:32:21.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:32:22.109+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:32:22.108+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:32:22.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.157 seconds
[2024-11-20T12:32:52.651+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:32:52.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:32:52.665+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:32:52.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:32:53.763+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:32:53.819+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:32:53.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:32:53.891+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:32:53.891+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:32:53.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.301 seconds
[2024-11-20T12:33:24.379+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:33:24.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:33:24.386+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:33:24.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:33:25.085+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:33:25.134+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:33:25.186+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:33:25.185+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:33:25.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.878 seconds
[2024-11-20T12:33:55.801+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:33:55.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:33:55.807+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:33:55.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:33:56.551+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:33:56.601+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:33:56.641+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:33:56.641+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:33:56.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.885 seconds
[2024-11-20T12:34:27.086+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:34:27.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:34:27.101+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:34:27.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:34:28.326+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:34:28.383+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:34:28.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:34:28.444+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:34:28.443+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:34:28.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.419 seconds
[2024-11-20T12:34:58.844+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:34:58.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:34:58.871+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:34:58.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:35:04.995+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:35:06.171+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:35:06.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:35:06.892+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:35:06.892+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:35:07.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 8.264 seconds
[2024-11-20T12:35:38.171+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:35:38.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:35:38.241+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:35:38.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:35:44.398+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:35:44.771+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:35:44.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:35:45.111+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:35:45.110+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:35:45.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 7.596 seconds
[2024-11-20T12:36:16.967+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:36:17.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:36:17.031+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:36:17.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:36:20.277+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:36:20.403+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:36:20.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:36:20.501+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:36:20.501+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:36:20.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.678 seconds
[2024-11-20T12:36:50.999+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:36:51.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:36:51.007+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:36:51.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:36:53.347+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:36:53.509+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:36:53.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:36:53.683+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:36:53.682+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:36:53.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.802 seconds
[2024-11-20T12:37:24.952+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:37:24.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:37:24.969+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:37:24.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:37:27.761+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:37:27.850+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:37:27.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:37:27.924+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:37:27.924+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:37:28.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.186 seconds
[2024-11-20T12:37:58.566+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:37:58.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:37:58.577+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:37:58.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:37:59.764+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:37:59.806+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:37:59.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:37:59.859+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:37:59.859+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:37:59.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.351 seconds
[2024-11-20T12:38:30.435+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:38:30.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:38:30.442+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:38:30.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:38:31.516+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:38:31.560+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:38:31.608+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:38:31.608+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:38:31.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.232 seconds
[2024-11-20T12:39:02.103+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:39:02.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:39:02.131+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:39:02.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:39:04.506+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:39:04.584+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:39:04.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:39:04.655+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:39:04.655+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:39:04.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.618 seconds
[2024-11-20T12:39:34.886+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:39:34.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:39:34.905+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:39:34.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:39:36.416+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:39:36.611+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:39:36.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:39:36.694+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:39:36.694+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:39:36.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.921 seconds
[2024-11-20T12:40:07.000+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:40:07.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:40:07.030+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:40:07.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:40:08.284+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:40:08.336+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:40:08.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:40:08.383+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:40:08.383+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:40:08.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.479 seconds
[2024-11-20T12:40:38.911+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:40:38.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:40:38.917+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:40:38.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:40:39.984+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:40:40.032+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:40:40.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:40:40.083+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:40:40.083+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:40:40.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.248 seconds
[2024-11-20T12:41:10.468+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:41:10.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:41:10.475+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:41:10.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:41:11.572+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:41:11.619+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:41:11.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:41:11.675+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:41:11.674+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:41:11.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.257 seconds
[2024-11-20T12:41:42.198+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:41:42.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:41:42.212+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:41:42.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:41:44.398+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:41:44.558+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:41:44.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:41:44.661+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:41:44.659+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:41:44.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.568 seconds
[2024-11-20T12:42:15.392+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:42:15.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:42:15.401+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:42:15.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:42:16.548+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:42:16.599+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:42:16.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:42:16.653+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:42:16.652+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:42:16.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.317 seconds
[2024-11-20T12:42:46.865+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:42:46.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:42:46.875+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:42:46.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:42:47.910+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:42:47.955+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:42:47.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:42:48.012+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:42:48.011+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:42:48.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.200 seconds
[2024-11-20T12:43:18.534+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:43:18.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:43:18.541+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:43:18.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:43:19.506+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:43:19.563+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:43:19.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:43:19.613+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:43:19.612+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:43:19.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.132 seconds
[2024-11-20T12:43:50.118+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:43:50.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:43:50.124+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:43:50.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:43:51.086+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:43:51.126+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:43:51.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:43:51.160+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:43:51.160+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:43:51.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.092 seconds
[2024-11-20T12:44:21.559+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:44:21.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:44:21.566+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:44:21.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:44:23.001+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:44:23.106+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:44:23.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:44:23.156+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:44:23.155+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:44:23.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.655 seconds
[2024-11-20T12:44:53.619+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:44:53.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:44:53.683+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:44:53.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:44:54.595+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:44:54.650+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:44:54.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:44:54.705+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:44:54.704+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:44:54.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.148 seconds
[2024-11-20T12:45:25.052+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:45:25.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:45:25.058+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:45:25.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:45:25.962+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:45:25.999+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:45:25.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:45:26.038+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:45:26.038+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:45:26.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.036 seconds
[2024-11-20T12:45:56.410+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:45:56.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:45:56.417+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:45:56.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:45:57.143+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:45:57.177+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:45:57.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:45:57.222+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:45:57.222+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:45:57.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.854 seconds
[2024-11-20T12:46:27.661+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:46:27.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:46:27.667+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:46:27.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:46:28.503+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:46:28.541+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:46:28.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:46:28.574+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:46:28.574+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:46:28.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.955 seconds
[2024-11-20T12:46:59.018+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:46:59.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:46:59.026+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:46:59.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:46:59.765+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:46:59.798+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:46:59.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:46:59.841+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:46:59.840+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:46:59.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.864 seconds
[2024-11-20T12:47:30.299+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:47:30.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:47:30.314+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:47:30.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:47:31.406+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:47:31.457+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:47:31.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:47:31.519+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:47:31.518+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:47:31.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.273 seconds
[2024-11-20T12:48:01.757+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:48:01.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:48:01.773+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:48:01.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:48:02.590+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:48:02.640+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:48:02.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:48:02.692+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:48:02.692+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:48:02.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.996 seconds
[2024-11-20T12:48:33.089+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:48:33.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:48:33.095+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:48:33.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:48:34.029+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:48:34.067+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:48:34.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:48:34.101+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:48:34.101+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:48:34.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.064 seconds
[2024-11-20T12:49:04.527+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:49:04.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:49:04.533+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:49:04.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:49:05.212+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:49:05.254+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:49:05.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:49:05.291+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:49:05.291+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:49:05.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.806 seconds
[2024-11-20T12:49:35.802+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:49:35.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:49:35.807+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:49:35.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:49:36.647+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:49:36.686+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:49:36.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:49:36.727+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:49:36.726+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:49:36.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.980 seconds
[2024-11-20T12:50:07.129+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:50:07.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:50:07.135+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:50:07.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:50:08.090+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:50:08.132+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:50:08.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:50:08.171+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:50:08.170+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:50:08.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.095 seconds
[2024-11-20T12:50:38.531+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:50:38.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:50:38.538+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:50:38.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:50:39.497+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:50:39.563+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:50:39.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:50:39.613+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:50:39.612+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:50:39.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.127 seconds
[2024-11-20T12:51:09.987+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:51:09.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:51:09.993+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:51:09.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:51:10.750+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:51:10.803+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:51:10.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:51:10.851+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:51:10.851+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:51:10.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.923 seconds
[2024-11-20T12:51:41.303+0000] {processor.py:186} INFO - Started process (PID=425) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:51:41.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:51:41.308+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:51:41.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:51:42.086+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:51:42.121+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:51:42.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:51:42.167+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:51:42.167+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:51:42.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.906 seconds
[2024-11-20T12:52:12.655+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:52:12.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:52:12.660+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:52:12.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:52:13.357+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:52:13.394+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:52:13.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:52:13.427+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:52:13.427+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:52:13.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.821 seconds
[2024-11-20T12:52:43.917+0000] {processor.py:186} INFO - Started process (PID=441) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:52:43.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:52:43.922+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:52:43.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:52:44.650+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:52:44.710+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:52:44.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:52:44.760+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:52:44.760+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:52:44.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.903 seconds
[2024-11-20T12:53:15.328+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:53:15.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:53:15.335+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:53:15.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:53:16.076+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:53:16.110+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:53:16.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:53:16.147+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:53:16.146+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:53:16.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.878 seconds
[2024-11-20T12:53:46.640+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:53:46.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:53:46.647+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:53:46.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:53:47.302+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:53:47.338+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:53:47.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:53:47.371+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:53:47.371+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:53:47.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.774 seconds
[2024-11-20T12:54:17.843+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:54:17.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:54:17.851+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:54:17.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:54:18.677+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:54:18.731+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:54:18.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:54:18.773+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:54:18.773+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:54:18.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.989 seconds
[2024-11-20T12:54:49.264+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:54:49.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:54:49.274+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:54:49.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:54:49.998+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:54:50.128+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:54:50.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:54:50.281+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:54:50.279+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:54:50.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.206 seconds
[2024-11-20T12:55:20.708+0000] {processor.py:186} INFO - Started process (PID=485) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:55:20.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:55:20.714+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:55:20.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:55:21.359+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:55:21.392+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:55:21.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:55:21.425+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:55:21.425+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:55:21.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.771 seconds
[2024-11-20T12:55:51.916+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:55:51.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:55:51.921+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:55:51.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:55:52.624+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:55:52.659+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:55:52.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:55:52.695+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:55:52.694+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:55:52.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.834 seconds
[2024-11-20T12:56:23.203+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:56:23.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:56:23.209+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:56:23.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:56:23.882+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:56:23.916+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:56:23.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:56:23.968+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:56:23.967+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:56:24.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.812 seconds
[2024-11-20T12:56:54.113+0000] {processor.py:186} INFO - Started process (PID=509) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:56:54.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:56:54.119+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:56:54.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:56:54.772+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:56:54.805+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:56:54.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:56:54.847+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:56:54.847+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:56:54.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.774 seconds
[2024-11-20T12:57:25.267+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:57:25.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:57:25.274+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:57:25.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:57:26.177+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:57:26.213+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:57:26.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:57:26.253+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:57:26.252+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:57:26.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.028 seconds
[2024-11-20T12:57:56.669+0000] {processor.py:186} INFO - Started process (PID=525) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:57:56.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:57:56.674+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:57:56.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:57:57.413+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:57:57.452+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:57:57.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:57:57.486+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:57:57.486+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:57:57.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.857 seconds
[2024-11-20T12:58:27.910+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:58:27.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:58:27.917+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:58:27.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:58:28.527+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:58:28.567+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:58:28.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:58:28.609+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:58:28.608+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:58:28.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.749 seconds
[2024-11-20T12:58:59.045+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:58:59.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:58:59.057+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:58:59.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:58:59.862+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:58:59.913+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:58:59.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:58:59.959+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:58:59.959+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:58:59.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.968 seconds
[2024-11-20T12:59:30.627+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:59:30.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T12:59:30.633+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:59:30.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:59:31.699+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T12:59:31.820+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:59:31.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T12:59:31.893+0000] {logging_mixin.py:190} INFO - [2024-11-20T12:59:31.893+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T12:59:31.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.358 seconds
[2024-11-20T13:00:02.210+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:00:02.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:00:02.216+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:00:02.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:00:03.015+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:00:03.053+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:00:03.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:00:03.093+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:00:03.092+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:00:03.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.924 seconds
[2024-11-20T13:00:33.513+0000] {processor.py:186} INFO - Started process (PID=566) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:00:33.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:00:33.520+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:00:33.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:00:34.344+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:00:34.377+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:00:34.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:00:34.410+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:00:34.410+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:00:34.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.950 seconds
[2024-11-20T13:01:04.857+0000] {processor.py:186} INFO - Started process (PID=574) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:01:04.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:01:04.864+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:01:04.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:01:05.581+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:01:05.616+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:01:05.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:01:05.651+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:01:05.651+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:01:05.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.834 seconds
[2024-11-20T13:01:36.083+0000] {processor.py:186} INFO - Started process (PID=582) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:01:36.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:01:36.088+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:01:36.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:01:36.750+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:01:36.783+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:01:36.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:01:36.837+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:01:36.836+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:01:36.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.796 seconds
[2024-11-20T13:02:07.255+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:02:07.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:02:07.267+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:02:07.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:02:08.001+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:02:08.047+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:02:08.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:02:08.090+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:02:08.089+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:02:08.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.888 seconds
[2024-11-20T13:02:38.505+0000] {processor.py:186} INFO - Started process (PID=598) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:02:38.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:02:38.510+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:02:38.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:02:39.158+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:02:39.191+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:02:39.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:02:39.226+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:02:39.226+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:02:39.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.766 seconds
[2024-11-20T13:03:09.406+0000] {processor.py:186} INFO - Started process (PID=606) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:03:09.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:03:09.412+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:03:09.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:03:10.093+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:03:10.151+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:03:10.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:03:10.200+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:03:10.200+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:03:10.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.850 seconds
[2024-11-20T13:03:40.767+0000] {processor.py:186} INFO - Started process (PID=613) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:03:40.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:03:40.776+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:03:40.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:03:41.488+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:03:41.533+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:03:41.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:03:41.571+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:03:41.571+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:03:41.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.860 seconds
[2024-11-20T13:04:12.061+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:04:12.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:04:12.066+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:04:12.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:04:12.707+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:04:12.751+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:04:12.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:04:12.788+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:04:12.787+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:04:12.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.764 seconds
[2024-11-20T13:04:43.176+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:04:43.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:04:43.182+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:04:43.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:04:44.025+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:04:44.060+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:04:44.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:04:44.097+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:04:44.097+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:04:44.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.962 seconds
[2024-11-20T13:05:14.553+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:05:14.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:05:14.559+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:05:14.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:05:15.230+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:05:15.265+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:05:15.264+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:05:15.300+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:05:15.300+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:05:15.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.790 seconds
[2024-11-20T13:05:45.698+0000] {processor.py:186} INFO - Started process (PID=645) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:05:45.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:05:45.704+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:05:45.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:05:46.545+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:05:46.605+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:05:46.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:05:46.668+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:05:46.668+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:05:46.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.029 seconds
[2024-11-20T13:06:17.047+0000] {processor.py:186} INFO - Started process (PID=654) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:06:17.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:06:17.053+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:06:17.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:06:17.782+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:06:17.815+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:06:17.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:06:17.850+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:06:17.850+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:06:17.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.858 seconds
[2024-11-20T13:06:48.270+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:06:48.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:06:48.276+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:06:48.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:06:48.950+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:06:48.981+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:06:48.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:06:49.020+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:06:49.019+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:06:49.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.801 seconds
[2024-11-20T13:07:19.451+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:07:19.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:07:19.467+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:07:19.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:07:20.378+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:07:20.444+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:07:20.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:07:20.488+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:07:20.487+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:07:20.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.090 seconds
[2024-11-20T13:07:50.771+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:07:50.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:07:50.777+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:07:50.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:07:51.545+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:07:51.588+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:07:51.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:07:51.625+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:07:51.625+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:07:51.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.897 seconds
[2024-11-20T13:08:22.000+0000] {processor.py:186} INFO - Started process (PID=687) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:08:22.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:08:22.005+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:08:22.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:08:22.809+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:08:22.842+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:08:22.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:08:22.875+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:08:22.875+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:08:22.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.940 seconds
[2024-11-20T13:08:53.326+0000] {processor.py:186} INFO - Started process (PID=695) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:08:53.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:08:53.332+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:08:53.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:08:54.194+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:08:54.224+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:08:54.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:08:54.276+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:08:54.275+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:08:54.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.994 seconds
[2024-11-20T13:09:24.843+0000] {processor.py:186} INFO - Started process (PID=710) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:09:24.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:09:24.855+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:09:24.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:09:25.772+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:09:25.813+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:09:25.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:09:25.857+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:09:25.856+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:09:25.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.058 seconds
[2024-11-20T13:09:56.158+0000] {processor.py:186} INFO - Started process (PID=718) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:09:56.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:09:56.165+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:09:56.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:09:56.912+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:09:56.952+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:09:56.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:09:56.994+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:09:56.993+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:09:57.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.879 seconds
[2024-11-20T13:10:27.393+0000] {processor.py:186} INFO - Started process (PID=725) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:10:27.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:10:27.398+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:10:27.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:10:28.163+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:10:28.196+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:10:28.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:10:28.244+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:10:28.244+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:10:28.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.894 seconds
[2024-11-20T13:10:58.734+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:10:58.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:10:58.740+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:10:58.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:10:59.723+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:10:59.761+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:10:59.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:10:59.795+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:10:59.794+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:10:59.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.168 seconds
[2024-11-20T13:11:30.256+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:11:30.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:11:30.261+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:11:30.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:11:31.082+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:11:31.141+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:11:31.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:11:31.183+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:11:31.183+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:11:31.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.979 seconds
[2024-11-20T13:12:01.604+0000] {processor.py:186} INFO - Started process (PID=749) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:12:01.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:12:01.609+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:12:01.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:12:02.303+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:12:02.336+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:12:02.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:12:02.389+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:12:02.388+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:12:02.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.826 seconds
[2024-11-20T13:12:32.823+0000] {processor.py:186} INFO - Started process (PID=758) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:12:32.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:12:32.829+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:12:32.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:12:33.653+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:12:33.692+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:12:33.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:12:33.726+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:12:33.726+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:12:33.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.954 seconds
[2024-11-20T13:13:04.165+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:13:04.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:13:04.171+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:13:04.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:13:04.911+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:13:04.943+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:13:04.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:13:04.993+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:13:04.992+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:13:05.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.869 seconds
[2024-11-20T13:13:35.468+0000] {processor.py:186} INFO - Started process (PID=774) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:13:35.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:13:35.475+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:13:35.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:13:36.279+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:13:36.361+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:13:36.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:13:36.406+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:13:36.406+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:13:36.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.988 seconds
[2024-11-20T13:14:06.799+0000] {processor.py:186} INFO - Started process (PID=783) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:14:06.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:14:06.804+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:14:06.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:14:07.598+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:14:07.632+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:14:07.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:14:07.665+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:14:07.665+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:14:07.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.907 seconds
[2024-11-20T13:14:38.243+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:14:38.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:14:38.248+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:14:38.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:14:38.968+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:14:39.025+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:14:39.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:14:39.061+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:14:39.061+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:14:39.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.867 seconds
[2024-11-20T13:15:09.568+0000] {processor.py:186} INFO - Started process (PID=799) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:15:09.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:15:09.577+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:15:09.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:15:10.430+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:15:10.468+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:15:10.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:15:10.502+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:15:10.502+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:15:10.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.972 seconds
[2024-11-20T13:15:40.968+0000] {processor.py:186} INFO - Started process (PID=807) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:15:40.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:15:40.977+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:15:40.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:15:41.809+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:15:41.889+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:15:41.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:15:41.933+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:15:41.932+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:15:41.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.035 seconds
[2024-11-20T13:16:12.359+0000] {processor.py:186} INFO - Started process (PID=815) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:16:12.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:16:12.365+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:16:12.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:16:13.298+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:16:13.336+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:16:13.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:16:13.379+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:16:13.379+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:16:13.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.064 seconds
[2024-11-20T13:16:43.750+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:16:43.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:16:43.756+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:16:43.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:16:44.519+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:16:44.559+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:16:44.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:16:44.593+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:16:44.592+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:16:44.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.926 seconds
[2024-11-20T13:17:15.104+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:17:15.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:17:15.118+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:17:15.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:17:16.245+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:17:16.286+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:17:16.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:17:16.323+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:17:16.323+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:17:16.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.294 seconds
[2024-11-20T13:17:46.510+0000] {processor.py:186} INFO - Started process (PID=838) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:17:46.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:17:46.516+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:17:46.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:17:47.213+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:17:47.255+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:17:47.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:17:47.297+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:17:47.296+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:17:47.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.866 seconds
[2024-11-20T13:18:17.738+0000] {processor.py:186} INFO - Started process (PID=847) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:18:17.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:18:17.743+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:18:17.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:18:18.582+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:18:18.619+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:18:18.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:18:18.654+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:18:18.654+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:18:18.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.956 seconds
[2024-11-20T13:18:49.062+0000] {processor.py:186} INFO - Started process (PID=856) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:18:49.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:18:49.068+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:18:49.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:18:49.694+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:18:49.728+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:18:49.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:18:49.763+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:18:49.763+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:18:49.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.741 seconds
[2024-11-20T13:19:20.369+0000] {processor.py:186} INFO - Started process (PID=865) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:19:20.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:19:20.376+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:19:20.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:19:21.373+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:19:21.414+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:19:21.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:19:21.466+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:19:21.466+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:19:21.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.158 seconds
[2024-11-20T13:19:51.839+0000] {processor.py:186} INFO - Started process (PID=874) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:19:51.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:19:51.844+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:19:51.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:19:52.638+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:19:52.685+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:19:52.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:19:52.731+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:19:52.730+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:19:54.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.982 seconds
[2024-11-20T13:20:25.219+0000] {processor.py:186} INFO - Started process (PID=882) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:20:25.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:20:25.225+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:20:25.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:20:26.353+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:20:26.387+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:20:26.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:20:26.428+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:20:26.428+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:20:26.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.250 seconds
[2024-11-20T13:20:56.851+0000] {processor.py:186} INFO - Started process (PID=891) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:20:56.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:20:56.858+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:20:56.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:20:57.980+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:20:58.118+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:20:58.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:20:58.191+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:20:58.191+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:20:58.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.382 seconds
[2024-11-20T13:21:28.636+0000] {processor.py:186} INFO - Started process (PID=905) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:21:28.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:21:28.643+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:21:28.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:21:29.476+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:21:29.531+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:21:29.530+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:21:29.587+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:21:29.587+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:21:29.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.016 seconds
[2024-11-20T13:21:59.976+0000] {processor.py:186} INFO - Started process (PID=913) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:21:59.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:21:59.983+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:21:59.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:22:00.754+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:22:00.789+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:22:00.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:22:00.839+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:22:00.839+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:22:00.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.905 seconds
[2024-11-20T13:22:31.306+0000] {processor.py:186} INFO - Started process (PID=921) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:22:31.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:22:31.313+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:22:31.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:22:32.067+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:22:32.104+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:22:32.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:22:32.142+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:22:32.141+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:22:32.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.135 seconds
[2024-11-20T13:23:02.687+0000] {processor.py:186} INFO - Started process (PID=930) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:23:02.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:23:02.692+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:23:02.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:23:03.423+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:23:03.461+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:23:03.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:23:03.496+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:23:03.496+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:23:03.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.864 seconds
[2024-11-20T13:23:33.903+0000] {processor.py:186} INFO - Started process (PID=938) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:23:33.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:23:33.909+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:23:33.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:23:34.676+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:23:34.723+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:23:34.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:23:34.770+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:23:34.770+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:23:34.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.913 seconds
[2024-11-20T13:24:05.943+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:24:05.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:24:05.984+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:24:05.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:24:08.705+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:24:08.820+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:24:08.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:24:08.925+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:24:08.924+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:24:09.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 3.108 seconds
[2024-11-20T13:24:39.935+0000] {processor.py:186} INFO - Started process (PID=954) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:24:39.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:24:39.945+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:24:39.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:24:41.037+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:24:41.111+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:24:41.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:24:41.179+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:24:41.179+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:24:41.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.312 seconds
[2024-11-20T13:25:11.417+0000] {processor.py:186} INFO - Started process (PID=962) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:25:11.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:25:11.424+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:25:11.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:25:12.207+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:25:12.246+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:25:12.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:25:12.299+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:25:12.298+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:25:12.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.304 seconds
[2024-11-20T13:25:43.080+0000] {processor.py:186} INFO - Started process (PID=970) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:25:43.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:25:43.085+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:25:43.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:25:43.830+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:25:43.869+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:25:43.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:25:43.909+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:25:43.908+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:25:43.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.869 seconds
[2024-11-20T13:26:14.102+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:26:14.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:26:14.107+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:26:14.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:26:14.939+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:26:14.977+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:26:14.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:26:15.012+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:26:15.012+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:26:15.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.964 seconds
[2024-11-20T13:26:45.461+0000] {processor.py:186} INFO - Started process (PID=985) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:26:45.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:26:45.467+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:26:45.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:26:46.318+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:26:46.351+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:26:46.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:26:46.384+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:26:46.384+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:26:46.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.971 seconds
[2024-11-20T13:27:16.880+0000] {processor.py:186} INFO - Started process (PID=992) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:27:16.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:27:16.891+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:27:16.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:27:17.842+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:27:17.874+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:27:17.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:27:17.927+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:27:17.926+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:27:17.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.101 seconds
[2024-11-20T13:27:48.318+0000] {processor.py:186} INFO - Started process (PID=1000) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:27:48.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:27:48.327+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:27:48.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:27:49.110+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:27:49.153+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:27:49.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:27:49.199+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:27:49.198+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:27:49.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.273 seconds
[2024-11-20T13:28:19.707+0000] {processor.py:186} INFO - Started process (PID=1008) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:28:19.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:28:19.714+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:28:19.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:28:20.612+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:28:20.656+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:28:20.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:28:20.702+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:28:20.702+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:28:20.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.039 seconds
[2024-11-20T13:28:51.081+0000] {processor.py:186} INFO - Started process (PID=1015) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:28:51.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:28:51.086+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:28:51.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:28:51.708+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:28:51.745+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:28:51.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:28:51.781+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:28:51.781+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:28:51.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.751 seconds
[2024-11-20T13:29:22.344+0000] {processor.py:186} INFO - Started process (PID=1024) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:29:22.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:29:22.354+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:29:22.353+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:29:23.082+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:29:23.118+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:29:23.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:29:23.150+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:29:23.150+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:29:23.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.863 seconds
[2024-11-20T13:29:53.598+0000] {processor.py:186} INFO - Started process (PID=1032) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:29:53.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:29:53.603+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:29:53.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:29:54.489+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:29:54.534+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:29:54.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:29:54.596+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:29:54.596+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:29:54.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.055 seconds
[2024-11-20T13:30:25.093+0000] {processor.py:186} INFO - Started process (PID=1040) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:30:25.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:30:25.099+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:30:25.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:30:25.867+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:30:25.905+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:30:25.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:30:25.937+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:30:25.937+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:30:26.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.163 seconds
[2024-11-20T13:30:56.586+0000] {processor.py:186} INFO - Started process (PID=1049) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:30:56.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:30:56.598+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:30:56.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:30:58.178+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:30:58.224+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:30:58.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:30:58.276+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:30:58.276+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:30:58.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.761 seconds
[2024-11-20T13:31:28.771+0000] {processor.py:186} INFO - Started process (PID=1057) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:31:28.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:31:28.778+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:31:28.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:31:30.199+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:31:30.450+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:31:30.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:31:30.537+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:31:30.536+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:31:30.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.854 seconds
[2024-11-20T13:32:01.104+0000] {processor.py:186} INFO - Started process (PID=1064) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:32:01.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:32:01.112+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:32:01.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:32:02.418+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:32:02.460+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:32:02.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:32:02.515+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:32:02.514+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:32:02.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.511 seconds
[2024-11-20T13:32:32.761+0000] {processor.py:186} INFO - Started process (PID=1078) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:32:32.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:32:32.767+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:32:32.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:32:33.781+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:32:33.823+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:32:33.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:32:33.876+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:32:33.876+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:32:33.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.162 seconds
[2024-11-20T13:33:04.096+0000] {processor.py:186} INFO - Started process (PID=1086) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:33:04.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:33:04.102+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:33:04.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:33:05.045+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:33:05.087+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:33:05.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:33:05.121+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:33:05.121+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:33:05.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.400 seconds
[2024-11-20T13:33:36.021+0000] {processor.py:186} INFO - Started process (PID=1094) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:33:36.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:33:36.035+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:33:36.952+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:33:36.991+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:33:36.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:33:37.337+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:33:37.336+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:33:37.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.375 seconds
[2024-11-20T13:34:07.732+0000] {processor.py:186} INFO - Started process (PID=1102) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:34:07.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:34:07.738+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:34:07.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:34:08.882+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:34:08.941+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:34:08.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:34:09.003+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:34:09.002+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:34:09.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.328 seconds
[2024-11-20T13:34:39.686+0000] {processor.py:186} INFO - Started process (PID=1110) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:34:39.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:34:39.692+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:34:39.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:34:41.276+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:34:41.450+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:34:41.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:34:41.547+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:34:41.544+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:34:41.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.945 seconds
[2024-11-20T13:35:12.084+0000] {processor.py:186} INFO - Started process (PID=1118) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:35:12.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:35:12.090+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:35:12.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:35:13.115+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:35:13.162+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:35:13.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:35:13.203+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:35:13.203+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:35:13.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.162 seconds
[2024-11-20T13:35:43.491+0000] {processor.py:186} INFO - Started process (PID=1125) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:35:43.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:35:43.497+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:35:43.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:35:44.586+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:35:44.635+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:35:44.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:35:44.679+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:35:44.679+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:35:45.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.611 seconds
[2024-11-20T13:36:15.543+0000] {processor.py:186} INFO - Started process (PID=1133) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:36:15.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:36:15.549+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:36:15.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:36:16.724+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:36:16.766+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:36:16.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:36:17.091+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:36:17.090+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:36:17.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.636 seconds
[2024-11-20T13:36:47.560+0000] {processor.py:186} INFO - Started process (PID=1141) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:36:47.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:36:47.565+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:36:47.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:36:48.710+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:36:48.752+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:36:48.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:36:48.791+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:36:48.790+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:36:48.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.276 seconds
[2024-11-20T13:37:19.164+0000] {processor.py:186} INFO - Started process (PID=1149) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:37:19.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:37:19.172+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:37:19.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:37:20.444+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:37:20.602+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:37:20.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:37:20.669+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:37:20.668+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:37:20.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.585 seconds
[2024-11-20T13:37:50.912+0000] {processor.py:186} INFO - Started process (PID=1157) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:37:50.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:37:50.923+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:37:50.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:37:51.775+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:37:51.818+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:37:51.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:37:51.858+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:37:51.858+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:37:51.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.010 seconds
[2024-11-20T13:38:22.474+0000] {processor.py:186} INFO - Started process (PID=1166) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:38:22.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:38:22.483+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:38:22.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:38:23.575+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:38:23.626+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:38:23.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:38:23.678+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:38:23.678+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:38:24.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.568 seconds
[2024-11-20T13:38:54.640+0000] {processor.py:186} INFO - Started process (PID=1174) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:38:54.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:38:54.646+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:38:54.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:38:55.776+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:38:55.820+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:38:55.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:38:56.152+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:38:56.152+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:38:56.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.557 seconds
[2024-11-20T13:39:27.223+0000] {processor.py:186} INFO - Started process (PID=1182) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:39:27.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:39:27.242+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:39:27.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:39:30.251+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:39:31.156+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:39:31.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:39:31.255+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:39:31.254+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:39:31.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 4.168 seconds
[2024-11-20T13:40:01.662+0000] {processor.py:186} INFO - Started process (PID=1190) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:40:01.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:40:01.678+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:40:01.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:40:05.414+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:40:05.675+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:40:05.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:40:05.764+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:40:05.764+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:40:05.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 4.208 seconds
[2024-11-20T13:40:36.208+0000] {processor.py:186} INFO - Started process (PID=1198) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:40:36.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:40:36.214+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:40:36.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:40:38.193+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:40:38.268+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:40:38.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:40:38.348+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:40:38.348+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:40:38.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.194 seconds
[2024-11-20T13:41:09.060+0000] {processor.py:186} INFO - Started process (PID=1211) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:41:09.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:41:09.065+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:41:09.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:41:10.294+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:41:10.333+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:41:10.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:41:10.367+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:41:10.366+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:41:10.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.589 seconds
[2024-11-20T13:41:41.120+0000] {processor.py:186} INFO - Started process (PID=1219) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:41:41.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:41:41.125+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:41:41.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:41:42.045+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:41:42.079+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:41:42.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:41:42.116+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:41:42.116+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:41:42.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.037 seconds
[2024-11-20T13:42:12.561+0000] {processor.py:186} INFO - Started process (PID=1227) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:42:12.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:42:12.567+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:42:12.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:42:13.535+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:42:13.569+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:42:13.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:42:13.617+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:42:13.617+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:42:13.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.093 seconds
[2024-11-20T13:42:43.979+0000] {processor.py:186} INFO - Started process (PID=1235) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:42:43.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:42:43.984+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:42:43.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:42:45.081+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:42:45.114+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:42:45.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:42:45.146+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:42:45.146+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:42:45.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.207 seconds
[2024-11-20T13:43:15.421+0000] {processor.py:186} INFO - Started process (PID=1243) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:43:15.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:43:15.427+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:43:15.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:43:17.091+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:43:17.498+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:43:17.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:43:17.578+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:43:17.577+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:43:17.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.210 seconds
[2024-11-20T13:43:47.998+0000] {processor.py:186} INFO - Started process (PID=1251) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:43:48.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:43:48.005+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:43:48.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:43:49.038+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:43:49.069+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:43:49.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:43:49.103+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:43:49.102+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:43:49.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.383 seconds
[2024-11-20T13:44:19.727+0000] {processor.py:186} INFO - Started process (PID=1260) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:44:19.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:44:19.733+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:44:19.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:44:21.048+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:44:21.090+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:44:21.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:44:21.503+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:44:21.502+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:44:21.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.814 seconds
[2024-11-20T13:44:51.983+0000] {processor.py:186} INFO - Started process (PID=1267) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:44:51.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:44:51.989+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:44:51.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:44:53.033+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:44:53.082+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:44:53.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:44:53.142+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:44:53.142+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:44:53.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.201 seconds
[2024-11-20T13:45:23.379+0000] {processor.py:186} INFO - Started process (PID=1275) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:45:23.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:45:23.384+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:45:23.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:45:24.359+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:45:24.407+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:45:24.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:45:24.458+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:45:24.458+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:45:24.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.123 seconds
[2024-11-20T13:45:54.918+0000] {processor.py:186} INFO - Started process (PID=1283) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:45:54.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:45:54.927+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:45:54.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:45:56.563+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:45:56.782+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:45:56.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:45:56.878+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:45:56.877+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:45:56.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.025 seconds
[2024-11-20T13:46:27.393+0000] {processor.py:186} INFO - Started process (PID=1291) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:46:27.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:46:27.401+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:46:27.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:46:28.979+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:46:29.092+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:46:29.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:46:29.183+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:46:29.183+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:46:29.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.564 seconds
[2024-11-20T13:47:00.420+0000] {processor.py:186} INFO - Started process (PID=1299) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:47:00.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:47:00.427+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:47:00.426+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:47:01.639+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:47:01.688+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:47:01.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:47:01.993+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:47:01.993+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:47:02.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.621 seconds
[2024-11-20T13:47:32.799+0000] {processor.py:186} INFO - Started process (PID=1306) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:47:32.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:47:32.805+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:47:32.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:47:33.815+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:47:33.852+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:47:33.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:47:33.887+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:47:33.887+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:47:33.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.135 seconds
[2024-11-20T13:48:04.261+0000] {processor.py:186} INFO - Started process (PID=1314) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:48:04.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:48:04.269+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:48:04.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:48:05.232+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:48:05.274+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:48:05.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:48:05.306+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:48:05.306+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:48:05.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.087 seconds
[2024-11-20T13:48:35.844+0000] {processor.py:186} INFO - Started process (PID=1322) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:48:35.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:48:35.849+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:48:35.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:48:36.967+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:48:37.002+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:48:37.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:48:37.036+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:48:37.036+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:48:37.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.230 seconds
[2024-11-20T13:49:07.325+0000] {processor.py:186} INFO - Started process (PID=1330) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:49:07.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:49:07.332+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:49:07.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:49:08.570+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:49:08.789+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:49:08.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:49:08.841+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:49:08.841+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:49:09.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.152 seconds
[2024-11-20T13:49:40.037+0000] {processor.py:186} INFO - Started process (PID=1337) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:49:40.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:49:40.042+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:49:40.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:49:41.327+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:49:41.386+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:49:41.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:49:41.685+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:49:41.684+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:49:41.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.691 seconds
[2024-11-20T13:50:12.278+0000] {processor.py:186} INFO - Started process (PID=1345) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:50:12.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:50:12.283+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:50:12.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:50:13.406+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:50:13.449+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:50:13.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:50:13.481+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:50:13.480+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:50:13.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.239 seconds
[2024-11-20T13:50:43.811+0000] {processor.py:186} INFO - Started process (PID=1352) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:50:43.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:50:43.816+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:50:43.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:50:45.191+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:50:45.225+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:50:45.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:50:45.264+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:50:45.264+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:50:45.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.491 seconds
[2024-11-20T13:51:16.156+0000] {processor.py:186} INFO - Started process (PID=1366) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:51:16.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:51:16.164+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:51:16.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:51:17.535+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:51:17.597+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:51:17.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:51:17.691+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:51:17.691+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:51:17.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.693 seconds
[2024-11-20T13:51:48.436+0000] {processor.py:186} INFO - Started process (PID=1375) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:51:48.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:51:48.442+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:51:48.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:51:49.378+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:51:49.419+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:51:49.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:51:49.452+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:51:49.451+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:51:49.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.347 seconds
[2024-11-20T13:52:20.193+0000] {processor.py:186} INFO - Started process (PID=1383) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:52:20.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:52:20.201+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:52:20.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:52:21.725+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:52:21.960+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:52:21.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:52:22.587+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:52:22.582+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:52:22.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.489 seconds
[2024-11-20T13:52:52.865+0000] {processor.py:186} INFO - Started process (PID=1391) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:52:52.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:52:52.872+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:52:52.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:52:53.947+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:52:53.994+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:52:53.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:52:54.029+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:52:54.029+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:52:54.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.220 seconds
[2024-11-20T13:53:05.057+0000] {processor.py:186} INFO - Started process (PID=1394) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:53:05.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:53:05.067+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:53:05.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:53:05.164+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:53:05.472+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:53:05.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:53:05.549+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:53:05.548+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:53:05.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.567 seconds
[2024-11-20T13:53:36.010+0000] {processor.py:186} INFO - Started process (PID=1400) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:53:36.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:53:36.016+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:53:36.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:53:36.069+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:53:36.115+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:53:36.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:53:36.156+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:53:36.155+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:53:36.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.185 seconds
[2024-11-20T13:54:06.786+0000] {processor.py:186} INFO - Started process (PID=1408) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:06.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:54:06.793+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:06.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:06.855+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:06.907+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:06.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:54:06.951+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:06.950+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:54:06.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.224 seconds
[2024-11-20T13:54:14.022+0000] {processor.py:186} INFO - Started process (PID=1409) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:14.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:54:14.028+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:14.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:14.078+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:14.115+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:14.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:54:14.151+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:14.150+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:54:14.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.194 seconds
[2024-11-20T13:54:44.742+0000] {processor.py:186} INFO - Started process (PID=1417) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:44.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:54:44.752+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:44.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:44.818+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:54:44.869+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:44.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:54:44.909+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:54:44.908+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:54:44.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.211 seconds
[2024-11-20T13:55:15.175+0000] {processor.py:186} INFO - Started process (PID=1425) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:55:15.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:55:15.181+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:55:15.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:55:15.218+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:55:15.256+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:55:15.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:55:15.290+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:55:15.290+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:55:15.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.155 seconds
[2024-11-20T13:55:46.087+0000] {processor.py:186} INFO - Started process (PID=1432) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:55:46.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:55:46.115+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:55:46.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:55:46.264+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:55:48.317+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:55:48.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:55:48.487+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:55:48.485+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:55:48.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 2.615 seconds
[2024-11-20T13:56:19.604+0000] {processor.py:186} INFO - Started process (PID=1439) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:56:19.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:56:19.614+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:56:19.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:56:19.740+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:56:20.006+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:56:20.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:56:20.113+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:56:20.104+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:56:20.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.661 seconds
[2024-11-20T13:56:50.516+0000] {processor.py:186} INFO - Started process (PID=1447) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:56:50.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:56:50.524+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:56:50.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:56:50.557+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:56:50.596+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:56:50.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:56:50.634+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:56:50.633+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:56:50.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.162 seconds
[2024-11-20T13:57:20.942+0000] {processor.py:186} INFO - Started process (PID=1454) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:57:20.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:57:20.949+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:57:20.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:57:21.040+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:57:21.081+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:57:21.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:57:21.125+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:57:21.124+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:57:21.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.236 seconds
[2024-11-20T13:57:51.717+0000] {processor.py:186} INFO - Started process (PID=1461) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:57:51.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T13:57:51.779+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:57:51.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:57:52.251+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T13:57:58.531+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:57:58.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T13:57:58.640+0000] {logging_mixin.py:190} INFO - [2024-11-20T13:57:58.640+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T13:57:58.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 7.074 seconds
[2024-11-20T14:00:21.337+0000] {processor.py:186} INFO - Started process (PID=1467) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:00:21.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:00:21.439+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:00:21.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:00:21.854+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:00:22.031+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:00:22.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:00:22.186+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:00:22.186+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:00:22.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.357 seconds
[2024-11-20T14:00:52.573+0000] {processor.py:186} INFO - Started process (PID=1474) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:00:52.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:00:52.580+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:00:52.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:00:52.629+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:00:52.703+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:00:52.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:00:52.799+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:00:52.798+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:00:52.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.298 seconds
[2024-11-20T14:01:23.113+0000] {processor.py:186} INFO - Started process (PID=1481) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:01:23.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:01:23.121+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:01:23.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:01:23.192+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:01:23.244+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:01:23.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:01:23.335+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:01:23.335+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:01:23.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.415 seconds
[2024-11-20T14:01:54.043+0000] {processor.py:186} INFO - Started process (PID=1493) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:01:54.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:01:54.056+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:01:54.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:01:54.180+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:01:54.318+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:01:54.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:01:54.411+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:01:54.410+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:01:54.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.489 seconds
[2024-11-20T14:02:24.806+0000] {processor.py:186} INFO - Started process (PID=1500) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:02:24.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:02:24.813+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:02:24.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:02:24.905+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:02:24.968+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:02:24.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:02:25.027+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:02:25.027+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:02:25.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.273 seconds
[2024-11-20T14:02:55.281+0000] {processor.py:186} INFO - Started process (PID=1507) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:02:55.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:02:55.288+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:02:55.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:02:55.335+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:02:55.392+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:02:55.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:02:55.452+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:02:55.451+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:02:55.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.230 seconds
[2024-11-20T14:03:25.672+0000] {processor.py:186} INFO - Started process (PID=1514) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:03:25.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:03:25.679+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:03:25.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:03:25.731+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:03:25.785+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:03:25.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:03:25.828+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:03:25.828+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:03:25.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.216 seconds
[2024-11-20T14:03:56.350+0000] {processor.py:186} INFO - Started process (PID=1521) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:03:56.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:03:56.355+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:03:56.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:03:56.390+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:03:56.428+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:03:56.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:03:56.462+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:03:56.461+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:03:56.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.163 seconds
[2024-11-20T14:04:26.899+0000] {processor.py:186} INFO - Started process (PID=1529) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:04:26.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:04:26.905+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:04:26.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:04:26.945+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:04:27.057+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:04:27.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:04:27.101+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:04:27.101+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:04:27.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.249 seconds
[2024-11-20T14:04:57.372+0000] {processor.py:186} INFO - Started process (PID=1537) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:04:57.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:04:57.378+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:04:57.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:04:57.408+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:04:57.451+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:04:57.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:04:57.490+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:04:57.490+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:04:57.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.166 seconds
[2024-11-20T14:05:27.905+0000] {processor.py:186} INFO - Started process (PID=1545) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:05:27.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:05:27.911+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:05:27.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:05:27.950+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:05:27.996+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:05:27.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:05:28.037+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:05:28.037+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:05:28.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.181 seconds
[2024-11-20T14:05:58.645+0000] {processor.py:186} INFO - Started process (PID=1551) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:05:58.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:05:58.652+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:05:58.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:05:58.687+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:05:58.750+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:05:58.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:05:58.815+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:05:58.814+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:05:58.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.230 seconds
[2024-11-20T14:06:29.393+0000] {processor.py:186} INFO - Started process (PID=1558) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:06:29.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:06:29.408+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:06:29.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:06:29.485+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:06:29.535+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:06:29.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:06:29.578+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:06:29.578+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:06:29.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.241 seconds
[2024-11-20T14:07:00.492+0000] {processor.py:186} INFO - Started process (PID=1565) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:07:00.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:07:00.498+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:07:00.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:07:00.536+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:07:00.577+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:07:00.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:07:00.610+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:07:00.610+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:07:00.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.170 seconds
[2024-11-20T14:07:31.297+0000] {processor.py:186} INFO - Started process (PID=1572) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:07:31.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:07:31.302+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:07:31.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:07:31.334+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:07:31.369+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:07:31.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:07:31.417+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:07:31.416+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:07:31.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.163 seconds
[2024-11-20T14:08:01.984+0000] {processor.py:186} INFO - Started process (PID=1578) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:08:01.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:08:01.990+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:08:01.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:08:02.048+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:08:02.226+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:08:02.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:08:02.331+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:08:02.331+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:08:02.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.473 seconds
[2024-11-20T14:08:32.893+0000] {processor.py:186} INFO - Started process (PID=1585) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:08:32.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:08:32.901+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:08:32.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:08:32.974+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:08:33.030+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:08:33.029+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:08:33.077+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:08:33.077+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:08:33.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.260 seconds
[2024-11-20T14:09:03.260+0000] {processor.py:186} INFO - Started process (PID=1592) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:09:03.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:09:03.268+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:09:03.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:09:03.308+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:09:03.361+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:09:03.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:09:03.405+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:09:03.405+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:09:03.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.205 seconds
[2024-11-20T14:09:33.562+0000] {processor.py:186} INFO - Started process (PID=1599) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:09:33.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:09:33.568+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:09:33.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:09:33.602+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:09:33.638+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:09:33.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:09:33.680+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:09:33.680+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:09:33.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.164 seconds
[2024-11-20T14:10:03.930+0000] {processor.py:186} INFO - Started process (PID=1606) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:10:03.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:10:03.936+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:10:03.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:10:03.968+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:10:04.016+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:10:04.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:10:04.071+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:10:04.071+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:10:04.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.198 seconds
[2024-11-20T14:10:34.566+0000] {processor.py:186} INFO - Started process (PID=1614) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:10:34.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:10:34.575+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:10:34.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:10:34.620+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:10:34.703+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:10:34.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:10:34.789+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:10:34.788+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:10:34.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.286 seconds
[2024-11-20T14:11:04.962+0000] {processor.py:186} INFO - Started process (PID=1621) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:11:04.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:11:04.970+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:11:04.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:11:05.020+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:11:05.130+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:11:05.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:11:05.175+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:11:05.174+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:11:05.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.259 seconds
[2024-11-20T14:11:35.639+0000] {processor.py:186} INFO - Started process (PID=1629) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:11:35.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:11:35.646+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:11:35.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:11:35.686+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:11:35.734+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:11:35.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:11:35.789+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:11:35.788+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:11:35.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.201 seconds
[2024-11-20T14:12:05.989+0000] {processor.py:186} INFO - Started process (PID=1636) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:12:05.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:12:05.996+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:12:05.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:12:06.052+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:12:06.092+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:12:06.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:12:06.135+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:12:06.134+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:12:06.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.199 seconds
[2024-11-20T14:12:36.540+0000] {processor.py:186} INFO - Started process (PID=1643) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:12:36.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:12:36.546+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:12:36.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:12:36.583+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:12:36.630+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:12:36.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:12:36.679+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:12:36.678+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:12:36.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.198 seconds
[2024-11-20T14:13:07.120+0000] {processor.py:186} INFO - Started process (PID=1651) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:13:07.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:13:07.126+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:13:07.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:13:07.163+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:13:07.202+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:13:07.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:13:07.240+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:13:07.240+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:13:07.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.162 seconds
[2024-11-20T14:13:37.535+0000] {processor.py:186} INFO - Started process (PID=1658) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:13:37.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:13:37.540+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:13:37.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:13:37.570+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:13:37.604+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:13:37.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:13:37.636+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:13:37.636+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:13:37.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.144 seconds
[2024-11-20T14:14:08.224+0000] {processor.py:186} INFO - Started process (PID=1665) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:14:08.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:14:08.233+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:14:08.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:14:08.377+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:14:08.505+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:14:08.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:14:08.598+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:14:08.598+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:14:08.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.471 seconds
[2024-11-20T14:14:37.805+0000] {processor.py:186} INFO - Started process (PID=1671) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:14:37.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:14:37.814+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:14:37.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:14:37.867+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:14:37.910+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:14:37.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:14:37.955+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:14:37.955+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:14:37.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.201 seconds
[2024-11-20T14:15:08.212+0000] {processor.py:186} INFO - Started process (PID=1678) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:15:08.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:15:08.218+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:15:08.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:15:08.248+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:15:08.283+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:15:08.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:15:08.317+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:15:08.317+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:15:08.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.152 seconds
[2024-11-20T14:15:38.757+0000] {processor.py:186} INFO - Started process (PID=1685) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:15:38.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:15:38.763+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:15:38.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:15:38.801+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:15:38.838+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:15:38.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:15:38.875+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:15:38.875+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:15:38.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.155 seconds
[2024-11-20T14:16:09.154+0000] {processor.py:186} INFO - Started process (PID=1692) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:16:09.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:16:09.160+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:16:09.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:16:09.190+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:16:09.225+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:16:09.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:16:09.259+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:16:09.259+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:16:09.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.145 seconds
[2024-11-20T14:16:39.664+0000] {processor.py:186} INFO - Started process (PID=1698) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:16:39.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:16:39.670+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:16:39.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:16:39.700+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:16:39.734+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:16:39.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:16:39.766+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:16:39.766+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:16:39.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.140 seconds
[2024-11-20T14:17:10.132+0000] {processor.py:186} INFO - Started process (PID=1705) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:17:10.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:17:10.137+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:17:10.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:17:10.165+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:17:10.200+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:17:10.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:17:10.234+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:17:10.233+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:17:10.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.140 seconds
[2024-11-20T14:17:40.645+0000] {processor.py:186} INFO - Started process (PID=1711) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:17:40.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:17:40.651+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:17:40.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:17:40.682+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:17:40.714+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:17:40.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:17:40.747+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:17:40.747+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:17:40.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.149 seconds
[2024-11-20T14:18:11.236+0000] {processor.py:186} INFO - Started process (PID=1717) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:18:11.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:18:11.243+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:18:11.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:18:11.278+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:18:11.322+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:18:11.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:18:11.369+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:18:11.368+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:18:11.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.177 seconds
[2024-11-20T14:18:41.634+0000] {processor.py:186} INFO - Started process (PID=1723) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:18:41.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:18:41.642+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:18:41.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:18:41.673+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:18:41.709+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:18:41.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:18:41.752+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:18:41.751+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:18:41.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.168 seconds
[2024-11-20T14:19:12.046+0000] {processor.py:186} INFO - Started process (PID=1730) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:19:12.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:19:12.052+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:19:12.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:19:12.093+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:19:12.171+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:19:12.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:19:12.240+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:19:12.239+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:19:12.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.247 seconds
[2024-11-20T14:19:42.658+0000] {processor.py:186} INFO - Started process (PID=1737) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:19:42.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:19:42.665+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:19:42.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:19:42.693+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:19:42.727+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:19:42.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:19:42.765+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:19:42.765+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:19:42.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.154 seconds
[2024-11-20T14:20:13.145+0000] {processor.py:186} INFO - Started process (PID=1744) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:20:13.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:20:13.150+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:20:13.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:20:13.181+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:20:13.215+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:20:13.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:20:13.249+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:20:13.248+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:20:13.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.151 seconds
[2024-11-20T14:20:43.673+0000] {processor.py:186} INFO - Started process (PID=1750) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:20:43.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:20:43.679+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:20:43.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:20:43.713+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:20:43.746+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:20:43.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:20:43.782+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:20:43.782+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:20:43.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.147 seconds
[2024-11-20T14:21:14.304+0000] {processor.py:186} INFO - Started process (PID=1757) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:21:14.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:21:14.309+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:21:14.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:21:14.347+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:21:14.383+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:21:14.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:21:14.422+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:21:14.422+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:21:14.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.158 seconds
[2024-11-20T14:21:44.813+0000] {processor.py:186} INFO - Started process (PID=1764) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:21:44.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:21:44.823+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:21:44.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:21:44.876+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:21:44.930+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:21:44.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:21:44.999+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:21:44.998+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:21:45.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.263 seconds
[2024-11-20T14:22:15.256+0000] {processor.py:186} INFO - Started process (PID=1771) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:22:15.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:22:15.262+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:22:15.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:22:15.299+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:22:15.347+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:22:15.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:22:15.389+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:22:15.389+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:22:15.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.177 seconds
[2024-11-20T14:22:45.693+0000] {processor.py:186} INFO - Started process (PID=1777) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:22:45.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:22:45.701+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:22:45.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:22:45.749+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:22:45.809+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:22:45.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:22:45.874+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:22:45.873+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:22:45.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.237 seconds
[2024-11-20T14:23:16.291+0000] {processor.py:186} INFO - Started process (PID=1784) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:23:16.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:23:16.298+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:23:16.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:23:16.331+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:23:16.368+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:23:16.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:23:16.413+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:23:16.412+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:23:16.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.165 seconds
[2024-11-20T14:23:46.805+0000] {processor.py:186} INFO - Started process (PID=1792) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:23:46.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:23:46.811+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:23:46.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:23:46.847+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:23:46.887+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:23:46.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:23:46.921+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:23:46.921+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:23:46.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.171 seconds
[2024-11-20T14:24:17.365+0000] {processor.py:186} INFO - Started process (PID=1800) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:24:17.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:24:17.378+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:24:17.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:24:17.433+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:24:17.511+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:24:17.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:24:17.586+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:24:17.586+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:24:17.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.302 seconds
[2024-11-20T14:24:48.049+0000] {processor.py:186} INFO - Started process (PID=1809) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:24:48.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:24:48.054+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:24:48.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:24:48.086+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:24:48.122+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:24:48.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:24:48.163+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:24:48.163+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:24:48.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.158 seconds
[2024-11-20T14:25:18.552+0000] {processor.py:186} INFO - Started process (PID=1817) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:25:18.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:25:18.558+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:25:18.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:25:18.592+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:25:18.628+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:25:18.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:25:18.713+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:25:18.712+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:25:18.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.251 seconds
[2024-11-20T14:25:49.012+0000] {processor.py:186} INFO - Started process (PID=1824) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:25:49.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:25:49.024+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:25:49.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:25:49.097+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:25:49.210+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:25:49.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:25:49.292+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:25:49.291+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:25:49.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.380 seconds
[2024-11-20T14:26:19.742+0000] {processor.py:186} INFO - Started process (PID=1831) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:26:19.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:26:19.748+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:26:19.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:26:19.784+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:26:19.821+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:26:19.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:26:19.863+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:26:19.863+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:26:19.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.165 seconds
[2024-11-20T14:26:50.270+0000] {processor.py:186} INFO - Started process (PID=1839) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:26:50.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:26:50.277+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:26:50.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:26:50.315+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:26:50.359+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:26:50.358+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:26:50.402+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:26:50.402+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:26:50.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.186 seconds
[2024-11-20T14:27:20.691+0000] {processor.py:186} INFO - Started process (PID=1846) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:27:20.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:27:20.700+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:27:20.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:27:20.749+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:27:20.802+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:27:20.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:27:20.847+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:27:20.847+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:27:20.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.204 seconds
[2024-11-20T14:27:51.189+0000] {processor.py:186} INFO - Started process (PID=1853) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:27:51.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:27:51.195+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:27:51.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:27:51.232+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:27:51.272+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:27:51.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:27:51.308+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:27:51.308+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:27:51.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.176 seconds
[2024-11-20T14:28:21.783+0000] {processor.py:186} INFO - Started process (PID=1860) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:28:21.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:28:21.788+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:28:21.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:28:21.822+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:28:21.863+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:28:21.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:28:21.898+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:28:21.898+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:28:21.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.161 seconds
[2024-11-20T14:28:52.273+0000] {processor.py:186} INFO - Started process (PID=1867) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:28:52.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:28:52.281+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:28:52.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:28:52.320+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:28:52.374+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:28:52.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:28:52.415+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:28:52.414+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:28:52.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.194 seconds
[2024-11-20T14:29:22.813+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:29:22.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:29:22.820+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:29:22.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:29:22.849+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:29:22.887+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:29:22.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:29:22.921+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:29:22.920+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:29:22.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.147 seconds
[2024-11-20T14:29:53.410+0000] {processor.py:186} INFO - Started process (PID=1881) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:29:53.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:29:53.415+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:29:53.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:29:53.442+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:29:53.475+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:29:53.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:29:53.507+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:29:53.507+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:29:53.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.137 seconds
[2024-11-20T14:30:23.921+0000] {processor.py:186} INFO - Started process (PID=1888) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:30:23.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:30:23.928+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:30:23.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:30:23.982+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:30:24.029+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:30:24.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:30:24.080+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:30:24.079+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:30:24.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.211 seconds
[2024-11-20T14:30:54.586+0000] {processor.py:186} INFO - Started process (PID=1896) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:30:54.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:30:54.592+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:30:54.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:30:54.620+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:30:54.652+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:30:54.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:30:54.684+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:30:54.683+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:30:54.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.135 seconds
[2024-11-20T14:31:25.078+0000] {processor.py:186} INFO - Started process (PID=1903) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:31:25.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:31:25.084+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:31:25.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:31:25.112+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:31:25.154+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:31:25.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:31:25.188+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:31:25.187+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:31:25.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.156 seconds
[2024-11-20T14:31:55.655+0000] {processor.py:186} INFO - Started process (PID=1909) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:31:55.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:31:55.660+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:31:55.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:31:55.690+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:31:55.725+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:31:55.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:31:55.758+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:31:55.758+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:31:55.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.142 seconds
[2024-11-20T14:32:26.133+0000] {processor.py:186} INFO - Started process (PID=1916) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:32:26.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:32:26.138+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:32:26.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:32:26.168+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:32:26.202+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:32:26.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:32:26.234+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:32:26.234+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:32:26.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.139 seconds
[2024-11-20T14:32:56.633+0000] {processor.py:186} INFO - Started process (PID=1923) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:32:56.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:32:56.639+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:32:56.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:32:56.678+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:32:56.712+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:32:56.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:32:56.744+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:32:56.744+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:32:56.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.150 seconds
[2024-11-20T14:33:27.096+0000] {processor.py:186} INFO - Started process (PID=1930) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:33:27.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:33:27.102+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:33:27.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:33:27.136+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:33:27.178+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:33:27.177+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:33:27.214+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:33:27.214+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:33:27.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.163 seconds
[2024-11-20T14:33:57.577+0000] {processor.py:186} INFO - Started process (PID=1937) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:33:57.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:33:57.584+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:33:57.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:33:57.614+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:33:57.648+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:33:57.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:33:57.681+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:33:57.681+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:33:57.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.157 seconds
[2024-11-20T14:34:28.088+0000] {processor.py:186} INFO - Started process (PID=1944) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:34:28.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:34:28.094+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:34:28.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:34:28.122+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:34:28.158+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:34:28.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:34:28.193+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:34:28.193+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:34:28.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.149 seconds
[2024-11-20T14:34:58.712+0000] {processor.py:186} INFO - Started process (PID=1951) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:34:58.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:34:58.718+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:34:58.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:34:58.752+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:34:58.788+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:34:58.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:34:58.823+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:34:58.822+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:34:58.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.163 seconds
[2024-11-20T14:35:29.256+0000] {processor.py:186} INFO - Started process (PID=1958) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:35:29.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:35:29.270+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:35:29.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:35:29.331+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:35:29.367+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:35:29.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:35:29.400+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:35:29.400+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:35:29.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.206 seconds
[2024-11-20T14:35:59.838+0000] {processor.py:186} INFO - Started process (PID=1964) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:35:59.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:35:59.843+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:35:59.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:35:59.876+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:35:59.910+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:35:59.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:35:59.942+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:35:59.942+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:35:59.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.143 seconds
[2024-11-20T14:36:30.390+0000] {processor.py:186} INFO - Started process (PID=1971) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:36:30.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:36:30.395+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:36:30.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:36:30.428+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:36:30.460+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:36:30.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:36:30.494+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:36:30.494+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:36:30.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.143 seconds
[2024-11-20T14:37:00.926+0000] {processor.py:186} INFO - Started process (PID=1978) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:37:00.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:37:00.932+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:37:00.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:37:00.963+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:37:00.995+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:37:00.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:37:01.030+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:37:01.029+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:37:01.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.141 seconds
[2024-11-20T14:37:31.452+0000] {processor.py:186} INFO - Started process (PID=1984) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:37:31.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:37:31.458+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:37:31.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:37:31.493+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:37:31.525+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:37:31.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:37:31.558+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:37:31.557+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:37:31.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.163 seconds
[2024-11-20T14:38:01.928+0000] {processor.py:186} INFO - Started process (PID=1991) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:38:01.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:38:01.936+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:38:01.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:38:01.973+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:38:02.021+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:38:02.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:38:02.062+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:38:02.062+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:38:02.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.182 seconds
[2024-11-20T14:38:32.519+0000] {processor.py:186} INFO - Started process (PID=1998) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:38:32.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:38:32.525+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:38:32.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:38:32.554+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:38:32.588+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:38:32.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:38:32.623+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:38:32.622+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:38:32.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.142 seconds
[2024-11-20T14:39:03.121+0000] {processor.py:186} INFO - Started process (PID=2005) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:39:03.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:39:03.128+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:39:03.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:39:03.167+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:39:03.213+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:39:03.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:39:03.269+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:39:03.268+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:39:03.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.204 seconds
[2024-11-20T14:39:33.616+0000] {processor.py:186} INFO - Started process (PID=2012) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:39:33.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:39:33.622+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:39:33.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:39:33.660+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:39:33.706+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:39:33.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:39:33.751+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:39:33.750+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:39:33.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.186 seconds
[2024-11-20T14:40:04.141+0000] {processor.py:186} INFO - Started process (PID=2019) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:40:04.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:40:04.146+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:40:04.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:40:04.176+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:40:04.209+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:40:04.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:40:04.242+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:40:04.242+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:40:04.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.149 seconds
[2024-11-20T14:40:34.896+0000] {processor.py:186} INFO - Started process (PID=2026) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:40:34.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:40:34.902+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:40:34.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:40:34.932+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:40:34.965+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:40:34.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:40:34.997+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:40:34.997+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:40:35.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.139 seconds
[2024-11-20T14:41:05.413+0000] {processor.py:186} INFO - Started process (PID=2033) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:41:05.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:41:05.420+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:41:05.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:41:05.452+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:41:05.491+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:41:05.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:41:05.532+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:41:05.531+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:41:05.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.157 seconds
[2024-11-20T14:41:35.992+0000] {processor.py:186} INFO - Started process (PID=2040) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:41:35.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:41:35.997+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:41:35.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:41:36.033+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:41:36.066+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:41:36.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:41:36.139+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:41:36.139+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:41:36.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.207 seconds
[2024-11-20T14:42:06.470+0000] {processor.py:186} INFO - Started process (PID=2053) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:42:06.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:42:06.475+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:42:06.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:42:06.506+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:42:06.539+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:42:06.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:42:06.571+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:42:06.571+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:42:06.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.150 seconds
[2024-11-20T14:42:37.093+0000] {processor.py:186} INFO - Started process (PID=2059) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:42:37.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:42:37.099+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:42:37.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:42:37.135+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:42:37.170+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:42:37.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:42:37.207+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:42:37.207+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:42:37.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.151 seconds
[2024-11-20T14:43:07.620+0000] {processor.py:186} INFO - Started process (PID=2066) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:43:07.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:43:07.626+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:43:07.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:43:07.659+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:43:07.691+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:43:07.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:43:07.724+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:43:07.723+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:43:07.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.161 seconds
[2024-11-20T14:43:38.249+0000] {processor.py:186} INFO - Started process (PID=2072) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:43:38.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:43:38.255+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:43:38.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:43:38.288+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:43:38.330+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:43:38.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:43:38.375+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:43:38.375+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:43:38.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.174 seconds
[2024-11-20T14:44:08.792+0000] {processor.py:186} INFO - Started process (PID=2079) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:44:08.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:44:08.800+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:44:08.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:44:08.829+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:44:08.865+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:44:08.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:44:08.899+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:44:08.899+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:44:08.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.145 seconds
[2024-11-20T14:44:39.140+0000] {processor.py:186} INFO - Started process (PID=2085) to work on /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:44:39.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-11-20T14:44:39.153+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:44:39.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:44:39.195+0000] {processor.py:925} INFO - DAG(s) 'weather_data_pipeline' retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-11-20T14:44:39.240+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:44:39.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-20T14:44:39.280+0000] {logging_mixin.py:190} INFO - [2024-11-20T14:44:39.279+0000] {dag.py:4180} INFO - Setting next_dagrun for weather_data_pipeline to 2024-11-20 00:00:00+00:00, run_after=2024-11-21 00:00:00+00:00
[2024-11-20T14:44:39.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.205 seconds
